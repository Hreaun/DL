{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTEOjNThhdBE"
      },
      "source": [
        "# Задание 3.1 - Сверточные нейронные сети (Convolutional Neural Networks)\n",
        "\n",
        "Это последнее задание на numpy, вы до него дожили! Остался последний марш-бросок, дальше только PyTorch.\n",
        "\n",
        "В этом задании вы реализуете свою собственную сверточную нейронную сеть."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wqPfEkWhlUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1637624f-d139-4b78-d2b4-9fd00cdc8d79"
      },
      "source": [
        "!git clone https://github.com/Hreaun/DL.git\n",
        "!cp DL/assignment3/*.py .\n",
        "!./DL/assignment3/download_data.sh\n",
        "!rm -rf DL"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DL' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[autoreload of layers failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ModuleNotFoundError: No module named 'assignment3'\n",
            "]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2021-03-30 02:37:39--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "Resolving ufldl.stanford.edu (ufldl.stanford.edu)... 171.64.68.10\n",
            "Connecting to ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2021-03-30 02:37:39--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "Reusing existing connection to ufldl.stanford.edu:80.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBGsH8D0hdBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1f620b-c7f9-4e75-ebba-54080bf475a7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6DcgFEbhdBo"
      },
      "source": [
        "from dataset import load_svhn, random_split_train_val\n",
        "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
        "from layers import FullyConnectedLayer, ReLULayer, ConvolutionalLayer, MaxPoolingLayer, Flattener\n",
        "from model import ConvNet\n",
        "from trainer import Trainer, Dataset\n",
        "from optim import SGD, MomentumSGD\n",
        "from metrics import multiclass_accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mIsZP3ChdBp"
      },
      "source": [
        "# Загружаем данные\n",
        "\n",
        "На этот раз мы не будем их преобразовывать в один вектор, а оставим размерности (num_samples, 32, 32, 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNVWVGxchdBq"
      },
      "source": [
        "def prepare_for_neural_network(train_X, test_X):    \n",
        "    train_X = train_X.astype(np.float) / 255.0\n",
        "    test_X = test_X.astype(np.float) / 255.0\n",
        "    \n",
        "    # Subtract mean\n",
        "    mean_image = np.mean(train_X, axis = 0)\n",
        "    train_X -= mean_image\n",
        "    test_X -= mean_image\n",
        "    \n",
        "    return train_X, test_X\n",
        "    \n",
        "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
        "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
        "# Split train into train and val\n",
        "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlLaSpnVhdBr"
      },
      "source": [
        "# Реализуем новые слои!\n",
        "\n",
        "Сначала основной новый слой - сверточный (Convolutional layer). \n",
        "Для начала мы реализуем его для только одного канала, а потом для нескольких.\n",
        "\n",
        "Сверточный слой выполняет операцию свертки (convolution) с весами для каждого канала, а потом складывает результаты. \n",
        "Возможно, поможет пересмотреть Лекцию 6 или внимательно прочитать\n",
        "http://cs231n.github.io/convolutional-networks/\n",
        "\n",
        "Один из подходов к реализации сверточного слоя основан на том, что для конкретного \"пикселя\" выхода применение сверточного слоя эквивалентно обычному полносвязному.  \n",
        "Рассмотрим один такой \"пиксель\":\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Он получает на вход   \n",
        "регион входа I размера `(batch_size, filter_size, filter_size, input_channels)`,  \n",
        "применяет к нему веса W `(filter_size, filter_size, input_channels, output_channels`\n",
        "и выдает `(batch_size, output_channels)`. \n",
        "\n",
        "Если:  \n",
        "- вход преобразовать в I' `(batch_size, filter_size*filter_size*input_channels)`,  \n",
        "- веса в W' `(filter_size*filter_size*input_channels, output_channels)`,  \n",
        "то выход \"пикселе\" будет эквивалентен полносвязному слою со входом I' и весами W'.\n",
        "\n",
        "Осталось выполнить его в цикле для каждого пикселя :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "F2RRCoqPhdBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0130da0c-4c37-43e9-8b4a-b3fde3962bea"
      },
      "source": [
        "# TODO: Implement ConvolutionaLayer that supports only 1 output and input channel\n",
        "\n",
        "# Note: now you're working with images, so X is 4-dimensional tensor of\n",
        "# (batch_size, height, width, channels)\n",
        "\n",
        "X = np.array([\n",
        "              [\n",
        "               [[1.0], [2.0]],\n",
        "               [[0.0], [-1.0]]\n",
        "              ]\n",
        "              ,\n",
        "              [\n",
        "               [[0.0], [1.0]],\n",
        "               [[-2.0], [-1.0]]\n",
        "              ]\n",
        "             ])\n",
        "\n",
        "# Batch of 2 images of dimensions 2x2 with a single channel\n",
        "print(\"Shape of X:\", X.shape)\n",
        "\n",
        "layer = ConvolutionalLayer(in_channels=1, out_channels=1, filter_size=2, padding=0)\n",
        "print(\"Shape of W\", layer.W.value.shape)\n",
        "layer.W.value = np.zeros_like(layer.W.value)\n",
        "layer.W.value[0, 0, 0, 0] = 1.0\n",
        "layer.B.value = np.ones_like(layer.B.value)\n",
        "result = layer.forward(X)\n",
        "\n",
        "assert result.shape == (2, 1, 1, 1)\n",
        "assert np.all(result == X[:, :1, :1, :1] + 1), \"result: %s, X: %s\" % (result, X[:, :1, :1, :1])\n",
        "\n",
        "\n",
        "# Now let's implement multiple output channels\n",
        "layer = ConvolutionalLayer(in_channels=1, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)\n",
        "\n",
        "\n",
        "# And now multple input channels!\n",
        "X = np.array([\n",
        "              [\n",
        "               [[1.0, 0.0], [2.0, 1.0]],\n",
        "               [[0.0, -1.0], [-1.0, -2.0]]\n",
        "              ]\n",
        "              ,\n",
        "              [\n",
        "               [[0.0, 1.0], [1.0, -1.0]],\n",
        "               [[-2.0, 2.0], [-1.0, 0.0]]\n",
        "              ]\n",
        "             ])\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X: (2, 2, 2, 1)\n",
            "Shape of W (2, 2, 1, 1)\n",
            "Shape of X: (2, 2, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQC-4KoKhdBt"
      },
      "source": [
        "## А теперь имплементируем обратный проход\n",
        "Возможно, это самое сложное место в курсе. Дальше будет лучше.\n",
        "\n",
        "Раз выполнение сверточного слоя эквивалентно полносвязному слою для каждого \"пикселя\" выхода, то общий обратный проход эквивалентен обратному проходу каждого из таких \"слоев\".  \n",
        "Градиенты от каждого из этих \"слоев\" в каждом пикселе надо сложить в соответствующие пиксели градиента по входу, а градиенты весов сложить все вместе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "qN-uTDHJhdBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2beafa-369b-4bc8-a2fc-6ce51d196188"
      },
      "source": [
        "# First test - check the shape is right\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "result = layer.forward(X)\n",
        "d_input = layer.backward(np.ones_like(result))\n",
        "assert d_input.shape == X.shape\n",
        "\n",
        "# Actually test the backward pass\n",
        "# As usual, you'll need to copy gradient check code from the previous assignment\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_gradient(layer, X)\n",
        "\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_param_gradient(layer, X, 'W')\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=2, padding=0)\n",
        "assert check_layer_param_gradient(layer, X, 'B')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n",
            "Gradient check passed!\n",
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewLn8J8HhdBv"
      },
      "source": [
        "Осталось реализовать дополнение нулями (padding).   \n",
        "Достаточно дополнить входной тензор нулями по сторонам. Не забудьте учесть это при обратном проходе!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TP5rY7xrhdBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1882130d-f090-42f3-c0d5-3644779aa707"
      },
      "source": [
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
        "result = layer.forward(X)\n",
        "# Note this kind of layer produces the same dimensions as input\n",
        "assert result.shape == X.shape,\"Result shape: %s - Expected shape %s\" % (result.shape, X.shape)\n",
        "d_input = layer.backward(np.ones_like(result))\n",
        "assert d_input.shape == X.shape\n",
        "layer = ConvolutionalLayer(in_channels=2, out_channels=2, filter_size=3, padding=1)\n",
        "assert check_layer_gradient(layer, X)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceiXbyK6hdBx"
      },
      "source": [
        "## После следующего слоя вам уже будет все ни по чем - max pooling\n",
        "\n",
        "Max Pooling - это слой, реализующий операцию максимума для каждого канала отдельно в окресности из `pool_size` \"пикселей\".\n",
        "\n",
        "![image](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
        "\n",
        "И напомним что такое stride.  \n",
        "Stride - это на сколько \"пикселей\" сдвигается окно на одном шаге.  \n",
        "Вот здесь, например, stride = 2\n",
        "\n",
        "![image.png](http://deeplearning.net/software/theano/_images/no_padding_strides.gif)\n",
        "\n",
        "На практике, для max pooling значение stride часто равно pool size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oV_fF8DhdBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6a9ab2-4945-4f40-819b-e78993b931a4"
      },
      "source": [
        "pool = MaxPoolingLayer(2, 2)\n",
        "result = pool.forward(X)\n",
        "assert result.shape == (2, 1, 1, 2)\n",
        "\n",
        "assert check_layer_gradient(pool, X)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcwoB2Q3hdBy"
      },
      "source": [
        "И на закуску - слой, преобразующий четырехмерные тензоры в двумерные.\n",
        "\n",
        "Этот слой понадобится нам, чтобы в конце сети перейти от сверточных слоев к полносвязным."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLwHhJvEhdBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20617c48-08e9-4b5e-c44b-bb330a0beed0"
      },
      "source": [
        "flattener = Flattener()\n",
        "result = flattener.forward(X)\n",
        "assert result.shape == (2,8)\n",
        "\n",
        "assert check_layer_gradient(flattener, X)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZI1dEmkhdBz"
      },
      "source": [
        "# Теперь есть все кирпичики, создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mbYx0LX2hdB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1cf97a-627f-4744-8650-22b833b91cdb"
      },
      "source": [
        "# TODO: In model.py, implement missed functions function for ConvNet model\n",
        "\n",
        "# No need to use L2 regularization\n",
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
        "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
        "\n",
        "# TODO Now implement backward pass and aggregate all of the params\n",
        "check_model_gradient(model, train_X[:2], train_y[:2])"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking gradient for conv1_W\n",
            "Gradient check passed!\n",
            "Checking gradient for conv1_B\n",
            "Gradient check passed!\n",
            "Checking gradient for conv2_W\n",
            "Gradient check passed!\n",
            "Checking gradient for conv2_B\n",
            "Gradient check passed!\n",
            "Checking gradient for fully_connected_W\n",
            "Gradient check passed!\n",
            "Checking gradient for fully_connected_B\n",
            "Gradient check passed!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpa9lDUOhdB3"
      },
      "source": [
        "# Оптимизатор и код для тренировки \n",
        "Должен заработать с кодом из прошлого задания без изменений!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fuhfMf-0hdB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2109c47e-6a1a-4f0e-a782-cd7cceaaaf8e"
      },
      "source": [
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, conv1_channels=2, conv2_channels=2)\n",
        "dataset = Dataset(train_X[:16], train_y[:16], val_X[:16], val_y[:16])\n",
        "trainer = Trainer(model, dataset, SGD(), batch_size=16, learning_rate=1e-4, num_epochs=50)\n",
        "\n",
        "loss_history, train_history, val_history = trainer.fit()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.301368, Train accuracy: 0.125000, val accuracy: 0.062500\n",
            "Loss: 2.301211, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.301055, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300899, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300743, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300587, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300432, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300276, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.300120, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299965, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299810, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299655, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299500, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299345, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299190, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.299035, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298881, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298727, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298572, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298418, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298264, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.298110, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297957, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297803, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297649, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297496, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297343, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297190, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.297037, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296884, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296731, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296578, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296426, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296273, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.296121, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295969, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295817, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295665, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295513, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295361, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295210, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.295058, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294907, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294756, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294605, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294454, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294303, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294152, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.294001, Train accuracy: 0.187500, val accuracy: 0.125000\n",
            "Loss: 2.293851, Train accuracy: 0.187500, val accuracy: 0.125000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpMWC7hXhdB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2969e819-e881-452e-b746-d21966d22cc2"
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(val_history)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa1eb27e850>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00MiHWIZhdB5"
      },
      "source": [
        "# Последнее упражнение\n",
        "В качестве последнего упражнения мы доведем точность на тренировочном наборе данных до 100% на небольшом наборе данных.\n",
        "Сверточные сети требуют большого количества вычислений и аккуратной эффективной реализации, поэтому настоящие модели мы будем тренировать уже на PyTorch в следующем задании."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbVVm6L5hdB6"
      },
      "source": [
        "## Итак, оверфитим маленький набор данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfR5XusBhdB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc0b105-9ecc-42b2-a2bd-d702c6f225a0"
      },
      "source": [
        "data_size = 128\n",
        "\n",
        "learning_rates = [1e-2, 1e-3]\n",
        "learning_rate_decays = [0.999, 0.95]\n",
        "conv_layer_sizes = [4, 8]\n",
        "batch_sizes = [8, 16]\n",
        "\n",
        "best_classifier = None\n",
        "best_train_accuracy = 0\n",
        "\n",
        "best_learning_rate = 0\n",
        "best_decay = 0\n",
        "best_conv_layer_size1 = 0\n",
        "best_conv_layer_size2 = 0\n",
        "best_batch_size = 0\n",
        "\n",
        "loss_history = []\n",
        "train_history = []\n",
        "val_history = []\n",
        "\n",
        "k = 1\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    for conv_layer_size1 in conv_layer_sizes:\n",
        "      for conv_layer_size2 in conv_layer_sizes:\n",
        "        for decay in learning_rate_decays:\n",
        "            for batch_size in batch_sizes:\n",
        "              model = ConvNet(input_shape=(32,32,3), n_output_classes=10, \n",
        "                              conv1_channels=conv_layer_size1,\n",
        "                              conv2_channels=conv_layer_size2)\n",
        "              dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
        "              # TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
        "              # Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
        "              trainer = Trainer(model, dataset, MomentumSGD(), \n",
        "                                learning_rate=learning_rate,\n",
        "                                num_epochs=50,\n",
        "                                batch_size=batch_size,\n",
        "                                learning_rate_decay=decay)\n",
        "              loss_history_cur, train_history_cur, val_history_cur = trainer.fit()\n",
        "              print(\"iteration\", k)\n",
        "              k += 1\n",
        "              if (train_history_cur[-1] > best_train_accuracy):\n",
        "                  loss_history = loss_history_cur\n",
        "                  train_history = train_history_cur\n",
        "                  val_history = val_history_cur\n",
        "\n",
        "                  best_learning_rate = learning_rate\n",
        "                  best_decay = decay\n",
        "                  best_conv_layer_size1 = conv_layer_size1\n",
        "                  best_conv_layer_size2 = conv_layer_size2\n",
        "                  best_batch_size = batch_size\n",
        "                  best_train_accuracy = train_history_cur[-1]\n",
        "                  best_classifier = model\n",
        "\n",
        "print('learning_rate={learning_rate}, decay={decay}, conv1={conv1}, conv2={conv2}, bs={bs}'\n",
        ".format(learning_rate=best_learning_rate,\n",
        "        decay=best_decay,\n",
        "        conv1=best_conv_layer_size1,\n",
        "        conv2=best_conv_layer_size2,\n",
        "        bs=best_batch_size\n",
        "        ))\n",
        "print('best train accuracy achieved: %f' % best_train_accuracy)\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.257040, Train accuracy: 0.179688, val accuracy: 0.203125\n",
            "Loss: 2.149921, Train accuracy: 0.203125, val accuracy: 0.203125\n",
            "Loss: 1.962860, Train accuracy: 0.218750, val accuracy: 0.242188\n",
            "Loss: 2.104959, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 1.977477, Train accuracy: 0.273438, val accuracy: 0.226562\n",
            "Loss: 1.785558, Train accuracy: 0.304688, val accuracy: 0.203125\n",
            "Loss: 2.055478, Train accuracy: 0.312500, val accuracy: 0.203125\n",
            "Loss: 1.931316, Train accuracy: 0.367188, val accuracy: 0.140625\n",
            "Loss: 1.689836, Train accuracy: 0.351562, val accuracy: 0.210938\n",
            "Loss: 1.997549, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 2.061876, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.688297, Train accuracy: 0.421875, val accuracy: 0.218750\n",
            "Loss: 1.648139, Train accuracy: 0.390625, val accuracy: 0.203125\n",
            "Loss: 1.463906, Train accuracy: 0.468750, val accuracy: 0.218750\n",
            "Loss: 1.481968, Train accuracy: 0.515625, val accuracy: 0.171875\n",
            "Loss: 1.993629, Train accuracy: 0.492188, val accuracy: 0.242188\n",
            "Loss: 2.147769, Train accuracy: 0.507812, val accuracy: 0.195312\n",
            "Loss: 1.360389, Train accuracy: 0.468750, val accuracy: 0.179688\n",
            "Loss: 1.822363, Train accuracy: 0.515625, val accuracy: 0.179688\n",
            "Loss: 1.567058, Train accuracy: 0.546875, val accuracy: 0.171875\n",
            "Loss: 1.596048, Train accuracy: 0.562500, val accuracy: 0.187500\n",
            "Loss: 1.626183, Train accuracy: 0.539062, val accuracy: 0.187500\n",
            "Loss: 1.694818, Train accuracy: 0.539062, val accuracy: 0.148438\n",
            "Loss: 1.417919, Train accuracy: 0.500000, val accuracy: 0.148438\n",
            "Loss: 1.400115, Train accuracy: 0.546875, val accuracy: 0.210938\n",
            "Loss: 1.205394, Train accuracy: 0.554688, val accuracy: 0.171875\n",
            "Loss: 1.103036, Train accuracy: 0.554688, val accuracy: 0.171875\n",
            "Loss: 1.123768, Train accuracy: 0.593750, val accuracy: 0.226562\n",
            "Loss: 1.258256, Train accuracy: 0.601562, val accuracy: 0.148438\n",
            "Loss: 0.878840, Train accuracy: 0.609375, val accuracy: 0.187500\n",
            "Loss: 1.027668, Train accuracy: 0.593750, val accuracy: 0.171875\n",
            "Loss: 0.933110, Train accuracy: 0.640625, val accuracy: 0.164062\n",
            "Loss: 1.139956, Train accuracy: 0.593750, val accuracy: 0.242188\n",
            "Loss: 1.843670, Train accuracy: 0.492188, val accuracy: 0.156250\n",
            "Loss: 0.852030, Train accuracy: 0.601562, val accuracy: 0.257812\n",
            "Loss: 1.129934, Train accuracy: 0.671875, val accuracy: 0.179688\n",
            "Loss: 1.056218, Train accuracy: 0.679688, val accuracy: 0.203125\n",
            "Loss: 1.144012, Train accuracy: 0.664062, val accuracy: 0.218750\n",
            "Loss: 0.870214, Train accuracy: 0.656250, val accuracy: 0.171875\n",
            "Loss: 1.299242, Train accuracy: 0.546875, val accuracy: 0.257812\n",
            "Loss: 1.533772, Train accuracy: 0.585938, val accuracy: 0.203125\n",
            "Loss: 0.781733, Train accuracy: 0.640625, val accuracy: 0.195312\n",
            "Loss: 1.213625, Train accuracy: 0.617188, val accuracy: 0.195312\n",
            "Loss: 0.833716, Train accuracy: 0.632812, val accuracy: 0.226562\n",
            "Loss: 0.801511, Train accuracy: 0.648438, val accuracy: 0.218750\n",
            "Loss: 1.865533, Train accuracy: 0.601562, val accuracy: 0.179688\n",
            "Loss: 0.793184, Train accuracy: 0.679688, val accuracy: 0.195312\n",
            "Loss: 0.850855, Train accuracy: 0.687500, val accuracy: 0.171875\n",
            "Loss: 1.135549, Train accuracy: 0.687500, val accuracy: 0.218750\n",
            "Loss: 1.299005, Train accuracy: 0.656250, val accuracy: 0.218750\n",
            "iteration 1\n",
            "Loss: 3.705992, Train accuracy: 0.156250, val accuracy: 0.101562\n",
            "Loss: 2.726785, Train accuracy: 0.125000, val accuracy: 0.085938\n",
            "Loss: 2.443351, Train accuracy: 0.187500, val accuracy: 0.179688\n",
            "Loss: 2.188228, Train accuracy: 0.257812, val accuracy: 0.101562\n",
            "Loss: 2.455748, Train accuracy: 0.218750, val accuracy: 0.132812\n",
            "Loss: 1.991556, Train accuracy: 0.234375, val accuracy: 0.210938\n",
            "Loss: 2.277756, Train accuracy: 0.234375, val accuracy: 0.218750\n",
            "Loss: 2.223493, Train accuracy: 0.226562, val accuracy: 0.203125\n",
            "Loss: 1.908194, Train accuracy: 0.234375, val accuracy: 0.226562\n",
            "Loss: 2.009239, Train accuracy: 0.359375, val accuracy: 0.179688\n",
            "Loss: 2.324592, Train accuracy: 0.304688, val accuracy: 0.179688\n",
            "Loss: 1.973924, Train accuracy: 0.375000, val accuracy: 0.179688\n",
            "Loss: 1.863098, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 2.028284, Train accuracy: 0.335938, val accuracy: 0.187500\n",
            "Loss: 1.721446, Train accuracy: 0.390625, val accuracy: 0.179688\n",
            "Loss: 1.547289, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 2.246599, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 1.786768, Train accuracy: 0.437500, val accuracy: 0.156250\n",
            "Loss: 1.632240, Train accuracy: 0.468750, val accuracy: 0.164062\n",
            "Loss: 1.977437, Train accuracy: 0.468750, val accuracy: 0.140625\n",
            "Loss: 1.996935, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.698373, Train accuracy: 0.515625, val accuracy: 0.187500\n",
            "Loss: 1.676877, Train accuracy: 0.515625, val accuracy: 0.179688\n",
            "Loss: 2.086756, Train accuracy: 0.484375, val accuracy: 0.164062\n",
            "Loss: 1.765750, Train accuracy: 0.492188, val accuracy: 0.164062\n",
            "Loss: 1.432466, Train accuracy: 0.484375, val accuracy: 0.210938\n",
            "Loss: 1.557388, Train accuracy: 0.523438, val accuracy: 0.156250\n",
            "Loss: 1.480721, Train accuracy: 0.546875, val accuracy: 0.218750\n",
            "Loss: 1.815109, Train accuracy: 0.531250, val accuracy: 0.148438\n",
            "Loss: 1.537161, Train accuracy: 0.492188, val accuracy: 0.226562\n",
            "Loss: 0.968301, Train accuracy: 0.578125, val accuracy: 0.132812\n",
            "Loss: 1.308717, Train accuracy: 0.593750, val accuracy: 0.171875\n",
            "Loss: 1.722694, Train accuracy: 0.500000, val accuracy: 0.148438\n",
            "Loss: 1.659629, Train accuracy: 0.570312, val accuracy: 0.148438\n",
            "Loss: 1.009578, Train accuracy: 0.617188, val accuracy: 0.156250\n",
            "Loss: 1.102249, Train accuracy: 0.601562, val accuracy: 0.164062\n",
            "Loss: 1.524244, Train accuracy: 0.648438, val accuracy: 0.187500\n",
            "Loss: 1.040104, Train accuracy: 0.617188, val accuracy: 0.179688\n",
            "Loss: 1.164075, Train accuracy: 0.640625, val accuracy: 0.164062\n",
            "Loss: 1.273571, Train accuracy: 0.601562, val accuracy: 0.210938\n",
            "Loss: 1.058787, Train accuracy: 0.687500, val accuracy: 0.148438\n",
            "Loss: 1.046208, Train accuracy: 0.687500, val accuracy: 0.210938\n",
            "Loss: 1.469783, Train accuracy: 0.671875, val accuracy: 0.140625\n",
            "Loss: 1.216650, Train accuracy: 0.710938, val accuracy: 0.171875\n",
            "Loss: 0.815358, Train accuracy: 0.648438, val accuracy: 0.148438\n",
            "Loss: 1.106087, Train accuracy: 0.648438, val accuracy: 0.140625\n",
            "Loss: 0.797379, Train accuracy: 0.757812, val accuracy: 0.156250\n",
            "Loss: 1.808363, Train accuracy: 0.679688, val accuracy: 0.195312\n",
            "Loss: 1.113556, Train accuracy: 0.703125, val accuracy: 0.171875\n",
            "Loss: 0.909189, Train accuracy: 0.625000, val accuracy: 0.195312\n",
            "iteration 2\n",
            "Loss: 2.574453, Train accuracy: 0.125000, val accuracy: 0.070312\n",
            "Loss: 2.313440, Train accuracy: 0.171875, val accuracy: 0.078125\n",
            "Loss: 2.125675, Train accuracy: 0.171875, val accuracy: 0.125000\n",
            "Loss: 1.973564, Train accuracy: 0.218750, val accuracy: 0.210938\n",
            "Loss: 2.220863, Train accuracy: 0.203125, val accuracy: 0.218750\n",
            "Loss: 2.009698, Train accuracy: 0.210938, val accuracy: 0.203125\n",
            "Loss: 1.899533, Train accuracy: 0.257812, val accuracy: 0.187500\n",
            "Loss: 2.058772, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 1.813909, Train accuracy: 0.242188, val accuracy: 0.171875\n",
            "Loss: 2.473027, Train accuracy: 0.250000, val accuracy: 0.164062\n",
            "Loss: 2.067342, Train accuracy: 0.257812, val accuracy: 0.179688\n",
            "Loss: 2.111907, Train accuracy: 0.265625, val accuracy: 0.171875\n",
            "Loss: 1.849211, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 1.850996, Train accuracy: 0.273438, val accuracy: 0.164062\n",
            "Loss: 1.970708, Train accuracy: 0.289062, val accuracy: 0.171875\n",
            "Loss: 2.372770, Train accuracy: 0.281250, val accuracy: 0.156250\n",
            "Loss: 2.233163, Train accuracy: 0.296875, val accuracy: 0.156250\n",
            "Loss: 1.736083, Train accuracy: 0.289062, val accuracy: 0.164062\n",
            "Loss: 2.308506, Train accuracy: 0.304688, val accuracy: 0.156250\n",
            "Loss: 2.010906, Train accuracy: 0.296875, val accuracy: 0.171875\n",
            "Loss: 2.167514, Train accuracy: 0.304688, val accuracy: 0.164062\n",
            "Loss: 2.252272, Train accuracy: 0.312500, val accuracy: 0.164062\n",
            "Loss: 1.887384, Train accuracy: 0.320312, val accuracy: 0.179688\n",
            "Loss: 2.036313, Train accuracy: 0.320312, val accuracy: 0.164062\n",
            "Loss: 2.223865, Train accuracy: 0.320312, val accuracy: 0.171875\n",
            "Loss: 1.749778, Train accuracy: 0.335938, val accuracy: 0.171875\n",
            "Loss: 1.992796, Train accuracy: 0.335938, val accuracy: 0.164062\n",
            "Loss: 2.261125, Train accuracy: 0.343750, val accuracy: 0.164062\n",
            "Loss: 2.119432, Train accuracy: 0.343750, val accuracy: 0.156250\n",
            "Loss: 2.178378, Train accuracy: 0.351562, val accuracy: 0.164062\n",
            "Loss: 1.860483, Train accuracy: 0.359375, val accuracy: 0.156250\n",
            "Loss: 1.722350, Train accuracy: 0.359375, val accuracy: 0.148438\n",
            "Loss: 2.310548, Train accuracy: 0.359375, val accuracy: 0.148438\n",
            "Loss: 1.871000, Train accuracy: 0.351562, val accuracy: 0.148438\n",
            "Loss: 1.919354, Train accuracy: 0.375000, val accuracy: 0.140625\n",
            "Loss: 1.898850, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.994542, Train accuracy: 0.359375, val accuracy: 0.132812\n",
            "Loss: 2.096834, Train accuracy: 0.375000, val accuracy: 0.140625\n",
            "Loss: 2.196838, Train accuracy: 0.375000, val accuracy: 0.140625\n",
            "Loss: 1.960796, Train accuracy: 0.382812, val accuracy: 0.140625\n",
            "Loss: 1.884154, Train accuracy: 0.375000, val accuracy: 0.132812\n",
            "Loss: 2.110210, Train accuracy: 0.382812, val accuracy: 0.140625\n",
            "Loss: 2.069252, Train accuracy: 0.375000, val accuracy: 0.140625\n",
            "Loss: 2.056672, Train accuracy: 0.382812, val accuracy: 0.132812\n",
            "Loss: 1.964061, Train accuracy: 0.367188, val accuracy: 0.132812\n",
            "Loss: 1.624650, Train accuracy: 0.382812, val accuracy: 0.140625\n",
            "Loss: 1.836184, Train accuracy: 0.375000, val accuracy: 0.140625\n",
            "Loss: 1.632800, Train accuracy: 0.382812, val accuracy: 0.140625\n",
            "Loss: 1.951104, Train accuracy: 0.382812, val accuracy: 0.132812\n",
            "Loss: 1.783259, Train accuracy: 0.382812, val accuracy: 0.140625\n",
            "iteration 3\n",
            "Loss: 2.460595, Train accuracy: 0.132812, val accuracy: 0.093750\n",
            "Loss: 2.337984, Train accuracy: 0.203125, val accuracy: 0.234375\n",
            "Loss: 2.066661, Train accuracy: 0.195312, val accuracy: 0.195312\n",
            "Loss: 2.061998, Train accuracy: 0.210938, val accuracy: 0.226562\n",
            "Loss: 2.086352, Train accuracy: 0.250000, val accuracy: 0.218750\n",
            "Loss: 1.974228, Train accuracy: 0.250000, val accuracy: 0.218750\n",
            "Loss: 2.368502, Train accuracy: 0.218750, val accuracy: 0.203125\n",
            "Loss: 2.061629, Train accuracy: 0.281250, val accuracy: 0.242188\n",
            "Loss: 1.934258, Train accuracy: 0.281250, val accuracy: 0.195312\n",
            "Loss: 2.038623, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.937663, Train accuracy: 0.328125, val accuracy: 0.226562\n",
            "Loss: 1.980599, Train accuracy: 0.351562, val accuracy: 0.179688\n",
            "Loss: 1.861189, Train accuracy: 0.273438, val accuracy: 0.210938\n",
            "Loss: 1.694807, Train accuracy: 0.320312, val accuracy: 0.234375\n",
            "Loss: 1.863164, Train accuracy: 0.351562, val accuracy: 0.164062\n",
            "Loss: 1.904804, Train accuracy: 0.343750, val accuracy: 0.218750\n",
            "Loss: 1.943135, Train accuracy: 0.359375, val accuracy: 0.226562\n",
            "Loss: 1.734771, Train accuracy: 0.390625, val accuracy: 0.164062\n",
            "Loss: 2.108227, Train accuracy: 0.335938, val accuracy: 0.210938\n",
            "Loss: 1.777941, Train accuracy: 0.375000, val accuracy: 0.187500\n",
            "Loss: 1.672417, Train accuracy: 0.390625, val accuracy: 0.218750\n",
            "Loss: 1.639694, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 1.828089, Train accuracy: 0.406250, val accuracy: 0.203125\n",
            "Loss: 1.489451, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 2.067450, Train accuracy: 0.398438, val accuracy: 0.179688\n",
            "Loss: 1.972091, Train accuracy: 0.445312, val accuracy: 0.171875\n",
            "Loss: 1.740820, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 2.051176, Train accuracy: 0.414062, val accuracy: 0.203125\n",
            "Loss: 1.523717, Train accuracy: 0.414062, val accuracy: 0.195312\n",
            "Loss: 1.559526, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.750964, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.800222, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.636126, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.611602, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.741463, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.649899, Train accuracy: 0.437500, val accuracy: 0.187500\n",
            "Loss: 1.736435, Train accuracy: 0.398438, val accuracy: 0.187500\n",
            "Loss: 1.441913, Train accuracy: 0.437500, val accuracy: 0.179688\n",
            "Loss: 1.754255, Train accuracy: 0.429688, val accuracy: 0.187500\n",
            "Loss: 1.685292, Train accuracy: 0.437500, val accuracy: 0.187500\n",
            "Loss: 1.737145, Train accuracy: 0.437500, val accuracy: 0.179688\n",
            "Loss: 1.580479, Train accuracy: 0.445312, val accuracy: 0.187500\n",
            "Loss: 1.627460, Train accuracy: 0.468750, val accuracy: 0.203125\n",
            "Loss: 1.636950, Train accuracy: 0.445312, val accuracy: 0.187500\n",
            "Loss: 1.707076, Train accuracy: 0.445312, val accuracy: 0.187500\n",
            "Loss: 1.765227, Train accuracy: 0.453125, val accuracy: 0.203125\n",
            "Loss: 1.501657, Train accuracy: 0.460938, val accuracy: 0.187500\n",
            "Loss: 1.506347, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.474024, Train accuracy: 0.445312, val accuracy: 0.179688\n",
            "Loss: 1.464552, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "iteration 4\n",
            "Loss: 2.463324, Train accuracy: 0.179688, val accuracy: 0.242188\n",
            "Loss: 3.011435, Train accuracy: 0.140625, val accuracy: 0.101562\n",
            "Loss: 2.376367, Train accuracy: 0.179688, val accuracy: 0.195312\n",
            "Loss: 2.048702, Train accuracy: 0.171875, val accuracy: 0.125000\n",
            "Loss: 2.243831, Train accuracy: 0.250000, val accuracy: 0.164062\n",
            "Loss: 2.234716, Train accuracy: 0.265625, val accuracy: 0.140625\n",
            "Loss: 2.071158, Train accuracy: 0.179688, val accuracy: 0.226562\n",
            "Loss: 1.588119, Train accuracy: 0.335938, val accuracy: 0.179688\n",
            "Loss: 2.080020, Train accuracy: 0.335938, val accuracy: 0.187500\n",
            "Loss: 2.275202, Train accuracy: 0.304688, val accuracy: 0.164062\n",
            "Loss: 2.299583, Train accuracy: 0.265625, val accuracy: 0.187500\n",
            "Loss: 1.857766, Train accuracy: 0.312500, val accuracy: 0.171875\n",
            "Loss: 1.837014, Train accuracy: 0.328125, val accuracy: 0.164062\n",
            "Loss: 2.000739, Train accuracy: 0.382812, val accuracy: 0.171875\n",
            "Loss: 1.931512, Train accuracy: 0.335938, val accuracy: 0.179688\n",
            "Loss: 2.096309, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 2.120403, Train accuracy: 0.398438, val accuracy: 0.070312\n",
            "Loss: 2.025558, Train accuracy: 0.406250, val accuracy: 0.171875\n",
            "Loss: 1.838743, Train accuracy: 0.429688, val accuracy: 0.156250\n",
            "Loss: 1.657680, Train accuracy: 0.468750, val accuracy: 0.125000\n",
            "Loss: 1.329234, Train accuracy: 0.398438, val accuracy: 0.164062\n",
            "Loss: 2.182410, Train accuracy: 0.468750, val accuracy: 0.125000\n",
            "Loss: 1.994437, Train accuracy: 0.445312, val accuracy: 0.179688\n",
            "Loss: 1.859988, Train accuracy: 0.507812, val accuracy: 0.140625\n",
            "Loss: 2.084260, Train accuracy: 0.500000, val accuracy: 0.140625\n",
            "Loss: 1.318337, Train accuracy: 0.453125, val accuracy: 0.226562\n",
            "Loss: 1.500910, Train accuracy: 0.546875, val accuracy: 0.164062\n",
            "Loss: 1.270827, Train accuracy: 0.632812, val accuracy: 0.125000\n",
            "Loss: 1.968086, Train accuracy: 0.570312, val accuracy: 0.187500\n",
            "Loss: 1.410750, Train accuracy: 0.546875, val accuracy: 0.117188\n",
            "Loss: 1.577563, Train accuracy: 0.609375, val accuracy: 0.164062\n",
            "Loss: 1.320903, Train accuracy: 0.578125, val accuracy: 0.093750\n",
            "Loss: 1.484844, Train accuracy: 0.601562, val accuracy: 0.156250\n",
            "Loss: 1.806450, Train accuracy: 0.625000, val accuracy: 0.171875\n",
            "Loss: 1.128823, Train accuracy: 0.648438, val accuracy: 0.125000\n",
            "Loss: 0.989243, Train accuracy: 0.640625, val accuracy: 0.179688\n",
            "Loss: 1.691118, Train accuracy: 0.664062, val accuracy: 0.132812\n",
            "Loss: 0.859397, Train accuracy: 0.609375, val accuracy: 0.140625\n",
            "Loss: 0.797730, Train accuracy: 0.679688, val accuracy: 0.109375\n",
            "Loss: 0.883823, Train accuracy: 0.718750, val accuracy: 0.164062\n",
            "Loss: 0.936568, Train accuracy: 0.671875, val accuracy: 0.132812\n",
            "Loss: 0.600433, Train accuracy: 0.609375, val accuracy: 0.156250\n",
            "Loss: 0.972807, Train accuracy: 0.695312, val accuracy: 0.117188\n",
            "Loss: 0.660071, Train accuracy: 0.679688, val accuracy: 0.125000\n",
            "Loss: 0.967186, Train accuracy: 0.789062, val accuracy: 0.148438\n",
            "Loss: 0.662090, Train accuracy: 0.773438, val accuracy: 0.140625\n",
            "Loss: 1.050343, Train accuracy: 0.796875, val accuracy: 0.164062\n",
            "Loss: 0.981810, Train accuracy: 0.820312, val accuracy: 0.140625\n",
            "Loss: 1.171932, Train accuracy: 0.757812, val accuracy: 0.132812\n",
            "Loss: 1.065738, Train accuracy: 0.773438, val accuracy: 0.171875\n",
            "iteration 5\n",
            "Loss: 2.914992, Train accuracy: 0.140625, val accuracy: 0.093750\n",
            "Loss: 2.664005, Train accuracy: 0.125000, val accuracy: 0.164062\n",
            "Loss: 2.116505, Train accuracy: 0.234375, val accuracy: 0.085938\n",
            "Loss: 1.833480, Train accuracy: 0.320312, val accuracy: 0.148438\n",
            "Loss: 1.574928, Train accuracy: 0.335938, val accuracy: 0.156250\n",
            "Loss: 1.784138, Train accuracy: 0.351562, val accuracy: 0.156250\n",
            "Loss: 1.675316, Train accuracy: 0.328125, val accuracy: 0.187500\n",
            "Loss: 1.798111, Train accuracy: 0.328125, val accuracy: 0.085938\n",
            "Loss: 2.038782, Train accuracy: 0.328125, val accuracy: 0.195312\n",
            "Loss: 2.070601, Train accuracy: 0.429688, val accuracy: 0.085938\n",
            "Loss: 1.853655, Train accuracy: 0.375000, val accuracy: 0.156250\n",
            "Loss: 1.574576, Train accuracy: 0.453125, val accuracy: 0.101562\n",
            "Loss: 1.769495, Train accuracy: 0.429688, val accuracy: 0.156250\n",
            "Loss: 1.730473, Train accuracy: 0.406250, val accuracy: 0.148438\n",
            "Loss: 1.763479, Train accuracy: 0.445312, val accuracy: 0.132812\n",
            "Loss: 1.582916, Train accuracy: 0.515625, val accuracy: 0.132812\n",
            "Loss: 1.939893, Train accuracy: 0.476562, val accuracy: 0.171875\n",
            "Loss: 1.512391, Train accuracy: 0.515625, val accuracy: 0.171875\n",
            "Loss: 1.705093, Train accuracy: 0.476562, val accuracy: 0.101562\n",
            "Loss: 2.008512, Train accuracy: 0.390625, val accuracy: 0.187500\n",
            "Loss: 1.000947, Train accuracy: 0.515625, val accuracy: 0.156250\n",
            "Loss: 1.489009, Train accuracy: 0.460938, val accuracy: 0.148438\n",
            "Loss: 1.771778, Train accuracy: 0.476562, val accuracy: 0.117188\n",
            "Loss: 1.238044, Train accuracy: 0.515625, val accuracy: 0.132812\n",
            "Loss: 1.729625, Train accuracy: 0.554688, val accuracy: 0.164062\n",
            "Loss: 1.667705, Train accuracy: 0.531250, val accuracy: 0.156250\n",
            "Loss: 1.451572, Train accuracy: 0.585938, val accuracy: 0.132812\n",
            "Loss: 1.005288, Train accuracy: 0.539062, val accuracy: 0.140625\n",
            "Loss: 1.598729, Train accuracy: 0.507812, val accuracy: 0.140625\n",
            "Loss: 1.384344, Train accuracy: 0.554688, val accuracy: 0.148438\n",
            "Loss: 1.313015, Train accuracy: 0.515625, val accuracy: 0.148438\n",
            "Loss: 1.510465, Train accuracy: 0.554688, val accuracy: 0.093750\n",
            "Loss: 1.276125, Train accuracy: 0.562500, val accuracy: 0.156250\n",
            "Loss: 1.404982, Train accuracy: 0.593750, val accuracy: 0.132812\n",
            "Loss: 1.437203, Train accuracy: 0.585938, val accuracy: 0.148438\n",
            "Loss: 1.472711, Train accuracy: 0.648438, val accuracy: 0.140625\n",
            "Loss: 1.554997, Train accuracy: 0.562500, val accuracy: 0.148438\n",
            "Loss: 1.484151, Train accuracy: 0.632812, val accuracy: 0.109375\n",
            "Loss: 1.286756, Train accuracy: 0.617188, val accuracy: 0.140625\n",
            "Loss: 1.209657, Train accuracy: 0.625000, val accuracy: 0.109375\n",
            "Loss: 1.475445, Train accuracy: 0.593750, val accuracy: 0.148438\n",
            "Loss: 1.350505, Train accuracy: 0.640625, val accuracy: 0.132812\n",
            "Loss: 1.054699, Train accuracy: 0.664062, val accuracy: 0.132812\n",
            "Loss: 1.203209, Train accuracy: 0.695312, val accuracy: 0.117188\n",
            "Loss: 1.092683, Train accuracy: 0.679688, val accuracy: 0.132812\n",
            "Loss: 1.152975, Train accuracy: 0.703125, val accuracy: 0.132812\n",
            "Loss: 0.880738, Train accuracy: 0.703125, val accuracy: 0.125000\n",
            "Loss: 0.634347, Train accuracy: 0.734375, val accuracy: 0.125000\n",
            "Loss: 0.832935, Train accuracy: 0.734375, val accuracy: 0.132812\n",
            "Loss: 1.269747, Train accuracy: 0.726562, val accuracy: 0.132812\n",
            "iteration 6\n",
            "Loss: 2.622027, Train accuracy: 0.210938, val accuracy: 0.234375\n",
            "Loss: 2.169797, Train accuracy: 0.195312, val accuracy: 0.250000\n",
            "Loss: 2.135663, Train accuracy: 0.226562, val accuracy: 0.179688\n",
            "Loss: 2.347767, Train accuracy: 0.273438, val accuracy: 0.273438\n",
            "Loss: 2.209394, Train accuracy: 0.320312, val accuracy: 0.234375\n",
            "Loss: 2.140310, Train accuracy: 0.328125, val accuracy: 0.218750\n",
            "Loss: 1.994299, Train accuracy: 0.414062, val accuracy: 0.257812\n",
            "Loss: 1.956716, Train accuracy: 0.351562, val accuracy: 0.265625\n",
            "Loss: 1.678081, Train accuracy: 0.406250, val accuracy: 0.250000\n",
            "Loss: 1.641875, Train accuracy: 0.445312, val accuracy: 0.250000\n",
            "Loss: 1.741681, Train accuracy: 0.421875, val accuracy: 0.250000\n",
            "Loss: 1.849889, Train accuracy: 0.445312, val accuracy: 0.234375\n",
            "Loss: 1.422946, Train accuracy: 0.492188, val accuracy: 0.242188\n",
            "Loss: 1.525446, Train accuracy: 0.500000, val accuracy: 0.218750\n",
            "Loss: 1.616789, Train accuracy: 0.468750, val accuracy: 0.234375\n",
            "Loss: 1.168793, Train accuracy: 0.476562, val accuracy: 0.234375\n",
            "Loss: 1.543453, Train accuracy: 0.500000, val accuracy: 0.234375\n",
            "Loss: 1.475521, Train accuracy: 0.500000, val accuracy: 0.265625\n",
            "Loss: 1.687846, Train accuracy: 0.515625, val accuracy: 0.218750\n",
            "Loss: 1.649580, Train accuracy: 0.539062, val accuracy: 0.250000\n",
            "Loss: 1.337526, Train accuracy: 0.578125, val accuracy: 0.250000\n",
            "Loss: 1.462663, Train accuracy: 0.578125, val accuracy: 0.257812\n",
            "Loss: 1.390861, Train accuracy: 0.562500, val accuracy: 0.257812\n",
            "Loss: 1.453807, Train accuracy: 0.585938, val accuracy: 0.250000\n",
            "Loss: 1.474160, Train accuracy: 0.593750, val accuracy: 0.242188\n",
            "Loss: 1.358189, Train accuracy: 0.609375, val accuracy: 0.250000\n",
            "Loss: 1.429723, Train accuracy: 0.609375, val accuracy: 0.234375\n",
            "Loss: 1.339010, Train accuracy: 0.617188, val accuracy: 0.257812\n",
            "Loss: 1.008987, Train accuracy: 0.617188, val accuracy: 0.257812\n",
            "Loss: 1.695993, Train accuracy: 0.625000, val accuracy: 0.250000\n",
            "Loss: 1.968607, Train accuracy: 0.632812, val accuracy: 0.234375\n",
            "Loss: 1.405035, Train accuracy: 0.656250, val accuracy: 0.257812\n",
            "Loss: 0.798405, Train accuracy: 0.640625, val accuracy: 0.250000\n",
            "Loss: 1.302183, Train accuracy: 0.656250, val accuracy: 0.242188\n",
            "Loss: 1.198637, Train accuracy: 0.656250, val accuracy: 0.242188\n",
            "Loss: 1.107517, Train accuracy: 0.640625, val accuracy: 0.273438\n",
            "Loss: 1.448241, Train accuracy: 0.656250, val accuracy: 0.265625\n",
            "Loss: 0.953104, Train accuracy: 0.671875, val accuracy: 0.226562\n",
            "Loss: 1.507879, Train accuracy: 0.671875, val accuracy: 0.250000\n",
            "Loss: 1.232919, Train accuracy: 0.664062, val accuracy: 0.257812\n",
            "Loss: 0.579764, Train accuracy: 0.687500, val accuracy: 0.250000\n",
            "Loss: 1.039832, Train accuracy: 0.664062, val accuracy: 0.226562\n",
            "Loss: 1.147922, Train accuracy: 0.671875, val accuracy: 0.242188\n",
            "Loss: 0.898732, Train accuracy: 0.679688, val accuracy: 0.242188\n",
            "Loss: 1.271424, Train accuracy: 0.679688, val accuracy: 0.250000\n",
            "Loss: 1.504100, Train accuracy: 0.679688, val accuracy: 0.242188\n",
            "Loss: 1.159633, Train accuracy: 0.679688, val accuracy: 0.242188\n",
            "Loss: 1.089084, Train accuracy: 0.671875, val accuracy: 0.242188\n",
            "Loss: 0.997215, Train accuracy: 0.679688, val accuracy: 0.242188\n",
            "Loss: 1.273544, Train accuracy: 0.671875, val accuracy: 0.234375\n",
            "iteration 7\n",
            "Loss: 1.951237, Train accuracy: 0.179688, val accuracy: 0.171875\n",
            "Loss: 2.452565, Train accuracy: 0.140625, val accuracy: 0.156250\n",
            "Loss: 2.724911, Train accuracy: 0.226562, val accuracy: 0.210938\n",
            "Loss: 2.063618, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.899744, Train accuracy: 0.265625, val accuracy: 0.195312\n",
            "Loss: 2.254510, Train accuracy: 0.289062, val accuracy: 0.179688\n",
            "Loss: 2.131736, Train accuracy: 0.304688, val accuracy: 0.164062\n",
            "Loss: 2.133709, Train accuracy: 0.289062, val accuracy: 0.195312\n",
            "Loss: 2.248831, Train accuracy: 0.335938, val accuracy: 0.156250\n",
            "Loss: 1.979426, Train accuracy: 0.367188, val accuracy: 0.195312\n",
            "Loss: 1.830085, Train accuracy: 0.367188, val accuracy: 0.125000\n",
            "Loss: 1.895361, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.985773, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 1.976896, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.905432, Train accuracy: 0.406250, val accuracy: 0.218750\n",
            "Loss: 1.612984, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 2.009215, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 1.617494, Train accuracy: 0.460938, val accuracy: 0.164062\n",
            "Loss: 1.743641, Train accuracy: 0.453125, val accuracy: 0.164062\n",
            "Loss: 1.701917, Train accuracy: 0.406250, val accuracy: 0.218750\n",
            "Loss: 1.749509, Train accuracy: 0.468750, val accuracy: 0.148438\n",
            "Loss: 1.893788, Train accuracy: 0.453125, val accuracy: 0.125000\n",
            "Loss: 1.875192, Train accuracy: 0.445312, val accuracy: 0.203125\n",
            "Loss: 1.709164, Train accuracy: 0.500000, val accuracy: 0.132812\n",
            "Loss: 1.830473, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.666458, Train accuracy: 0.468750, val accuracy: 0.179688\n",
            "Loss: 1.469604, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.522936, Train accuracy: 0.500000, val accuracy: 0.164062\n",
            "Loss: 1.213155, Train accuracy: 0.492188, val accuracy: 0.171875\n",
            "Loss: 1.457326, Train accuracy: 0.515625, val accuracy: 0.171875\n",
            "Loss: 1.585935, Train accuracy: 0.515625, val accuracy: 0.164062\n",
            "Loss: 1.212466, Train accuracy: 0.500000, val accuracy: 0.171875\n",
            "Loss: 1.566839, Train accuracy: 0.546875, val accuracy: 0.132812\n",
            "Loss: 1.661576, Train accuracy: 0.515625, val accuracy: 0.179688\n",
            "Loss: 1.458250, Train accuracy: 0.492188, val accuracy: 0.164062\n",
            "Loss: 1.525630, Train accuracy: 0.523438, val accuracy: 0.148438\n",
            "Loss: 1.524860, Train accuracy: 0.539062, val accuracy: 0.156250\n",
            "Loss: 1.890148, Train accuracy: 0.531250, val accuracy: 0.171875\n",
            "Loss: 1.581504, Train accuracy: 0.531250, val accuracy: 0.171875\n",
            "Loss: 1.500655, Train accuracy: 0.523438, val accuracy: 0.164062\n",
            "Loss: 1.479340, Train accuracy: 0.523438, val accuracy: 0.156250\n",
            "Loss: 1.384962, Train accuracy: 0.546875, val accuracy: 0.148438\n",
            "Loss: 0.912522, Train accuracy: 0.546875, val accuracy: 0.156250\n",
            "Loss: 1.468840, Train accuracy: 0.531250, val accuracy: 0.156250\n",
            "Loss: 1.422891, Train accuracy: 0.531250, val accuracy: 0.148438\n",
            "Loss: 1.391886, Train accuracy: 0.531250, val accuracy: 0.164062\n",
            "Loss: 1.242941, Train accuracy: 0.546875, val accuracy: 0.156250\n",
            "Loss: 1.536594, Train accuracy: 0.554688, val accuracy: 0.156250\n",
            "Loss: 1.442670, Train accuracy: 0.562500, val accuracy: 0.164062\n",
            "Loss: 1.660617, Train accuracy: 0.539062, val accuracy: 0.164062\n",
            "iteration 8\n",
            "Loss: 2.791992, Train accuracy: 0.093750, val accuracy: 0.039062\n",
            "Loss: 2.620863, Train accuracy: 0.187500, val accuracy: 0.195312\n",
            "Loss: 2.171978, Train accuracy: 0.179688, val accuracy: 0.265625\n",
            "Loss: 1.918284, Train accuracy: 0.195312, val accuracy: 0.210938\n",
            "Loss: 2.313027, Train accuracy: 0.203125, val accuracy: 0.195312\n",
            "Loss: 2.039617, Train accuracy: 0.195312, val accuracy: 0.195312\n",
            "Loss: 2.171150, Train accuracy: 0.234375, val accuracy: 0.234375\n",
            "Loss: 2.003586, Train accuracy: 0.296875, val accuracy: 0.218750\n",
            "Loss: 2.221080, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 1.879558, Train accuracy: 0.296875, val accuracy: 0.218750\n",
            "Loss: 2.105710, Train accuracy: 0.328125, val accuracy: 0.203125\n",
            "Loss: 2.119594, Train accuracy: 0.359375, val accuracy: 0.171875\n",
            "Loss: 1.768967, Train accuracy: 0.398438, val accuracy: 0.210938\n",
            "Loss: 1.626780, Train accuracy: 0.398438, val accuracy: 0.210938\n",
            "Loss: 1.948211, Train accuracy: 0.414062, val accuracy: 0.187500\n",
            "Loss: 1.790931, Train accuracy: 0.390625, val accuracy: 0.234375\n",
            "Loss: 1.939907, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 1.835675, Train accuracy: 0.414062, val accuracy: 0.156250\n",
            "Loss: 1.342793, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.681644, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.508586, Train accuracy: 0.429688, val accuracy: 0.171875\n",
            "Loss: 1.479783, Train accuracy: 0.445312, val accuracy: 0.164062\n",
            "Loss: 2.104087, Train accuracy: 0.468750, val accuracy: 0.164062\n",
            "Loss: 1.520603, Train accuracy: 0.484375, val accuracy: 0.187500\n",
            "Loss: 1.646559, Train accuracy: 0.492188, val accuracy: 0.164062\n",
            "Loss: 1.422356, Train accuracy: 0.507812, val accuracy: 0.171875\n",
            "Loss: 1.941810, Train accuracy: 0.515625, val accuracy: 0.226562\n",
            "Loss: 0.764545, Train accuracy: 0.531250, val accuracy: 0.171875\n",
            "Loss: 1.215838, Train accuracy: 0.562500, val accuracy: 0.164062\n",
            "Loss: 1.591973, Train accuracy: 0.484375, val accuracy: 0.164062\n",
            "Loss: 1.712005, Train accuracy: 0.500000, val accuracy: 0.132812\n",
            "Loss: 1.583361, Train accuracy: 0.500000, val accuracy: 0.203125\n",
            "Loss: 0.987618, Train accuracy: 0.593750, val accuracy: 0.171875\n",
            "Loss: 0.902810, Train accuracy: 0.578125, val accuracy: 0.164062\n",
            "Loss: 0.998832, Train accuracy: 0.539062, val accuracy: 0.195312\n",
            "Loss: 1.208933, Train accuracy: 0.617188, val accuracy: 0.140625\n",
            "Loss: 0.947787, Train accuracy: 0.609375, val accuracy: 0.132812\n",
            "Loss: 1.423392, Train accuracy: 0.632812, val accuracy: 0.179688\n",
            "Loss: 1.371306, Train accuracy: 0.625000, val accuracy: 0.171875\n",
            "Loss: 0.885846, Train accuracy: 0.679688, val accuracy: 0.156250\n",
            "Loss: 0.856807, Train accuracy: 0.664062, val accuracy: 0.132812\n",
            "Loss: 1.101105, Train accuracy: 0.671875, val accuracy: 0.148438\n",
            "Loss: 1.402663, Train accuracy: 0.695312, val accuracy: 0.148438\n",
            "Loss: 0.800632, Train accuracy: 0.648438, val accuracy: 0.156250\n",
            "Loss: 1.047009, Train accuracy: 0.687500, val accuracy: 0.148438\n",
            "Loss: 1.222705, Train accuracy: 0.648438, val accuracy: 0.148438\n",
            "Loss: 1.698924, Train accuracy: 0.617188, val accuracy: 0.164062\n",
            "Loss: 1.359227, Train accuracy: 0.687500, val accuracy: 0.164062\n",
            "Loss: 0.898236, Train accuracy: 0.742188, val accuracy: 0.148438\n",
            "Loss: 1.209937, Train accuracy: 0.718750, val accuracy: 0.156250\n",
            "iteration 9\n",
            "Loss: 2.637310, Train accuracy: 0.101562, val accuracy: 0.171875\n",
            "Loss: 2.336797, Train accuracy: 0.171875, val accuracy: 0.078125\n",
            "Loss: 2.418091, Train accuracy: 0.218750, val accuracy: 0.093750\n",
            "Loss: 2.577255, Train accuracy: 0.226562, val accuracy: 0.210938\n",
            "Loss: 2.313982, Train accuracy: 0.210938, val accuracy: 0.164062\n",
            "Loss: 2.154736, Train accuracy: 0.289062, val accuracy: 0.195312\n",
            "Loss: 2.396779, Train accuracy: 0.312500, val accuracy: 0.203125\n",
            "Loss: 1.979445, Train accuracy: 0.351562, val accuracy: 0.171875\n",
            "Loss: 2.029312, Train accuracy: 0.375000, val accuracy: 0.187500\n",
            "Loss: 1.810165, Train accuracy: 0.414062, val accuracy: 0.218750\n",
            "Loss: 1.722011, Train accuracy: 0.382812, val accuracy: 0.171875\n",
            "Loss: 1.592040, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.747403, Train accuracy: 0.445312, val accuracy: 0.148438\n",
            "Loss: 1.735300, Train accuracy: 0.429688, val accuracy: 0.171875\n",
            "Loss: 1.800835, Train accuracy: 0.476562, val accuracy: 0.195312\n",
            "Loss: 1.632016, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.555894, Train accuracy: 0.460938, val accuracy: 0.164062\n",
            "Loss: 1.642121, Train accuracy: 0.500000, val accuracy: 0.179688\n",
            "Loss: 1.772244, Train accuracy: 0.453125, val accuracy: 0.164062\n",
            "Loss: 1.454721, Train accuracy: 0.539062, val accuracy: 0.195312\n",
            "Loss: 1.510416, Train accuracy: 0.523438, val accuracy: 0.203125\n",
            "Loss: 1.867383, Train accuracy: 0.515625, val accuracy: 0.171875\n",
            "Loss: 1.677613, Train accuracy: 0.546875, val accuracy: 0.179688\n",
            "Loss: 1.749680, Train accuracy: 0.546875, val accuracy: 0.210938\n",
            "Loss: 1.490948, Train accuracy: 0.546875, val accuracy: 0.179688\n",
            "Loss: 0.982345, Train accuracy: 0.554688, val accuracy: 0.187500\n",
            "Loss: 1.389368, Train accuracy: 0.531250, val accuracy: 0.187500\n",
            "Loss: 1.089909, Train accuracy: 0.562500, val accuracy: 0.195312\n",
            "Loss: 1.353247, Train accuracy: 0.507812, val accuracy: 0.171875\n",
            "Loss: 1.184290, Train accuracy: 0.546875, val accuracy: 0.195312\n",
            "Loss: 1.120580, Train accuracy: 0.578125, val accuracy: 0.187500\n",
            "Loss: 1.328112, Train accuracy: 0.617188, val accuracy: 0.210938\n",
            "Loss: 1.234034, Train accuracy: 0.617188, val accuracy: 0.195312\n",
            "Loss: 1.077614, Train accuracy: 0.601562, val accuracy: 0.187500\n",
            "Loss: 1.260959, Train accuracy: 0.601562, val accuracy: 0.203125\n",
            "Loss: 1.362025, Train accuracy: 0.609375, val accuracy: 0.210938\n",
            "Loss: 1.223163, Train accuracy: 0.640625, val accuracy: 0.203125\n",
            "Loss: 1.392113, Train accuracy: 0.609375, val accuracy: 0.203125\n",
            "Loss: 1.030133, Train accuracy: 0.632812, val accuracy: 0.187500\n",
            "Loss: 1.284538, Train accuracy: 0.585938, val accuracy: 0.179688\n",
            "Loss: 1.232787, Train accuracy: 0.656250, val accuracy: 0.195312\n",
            "Loss: 0.785295, Train accuracy: 0.664062, val accuracy: 0.210938\n",
            "Loss: 1.116585, Train accuracy: 0.632812, val accuracy: 0.179688\n",
            "Loss: 1.671739, Train accuracy: 0.617188, val accuracy: 0.203125\n",
            "Loss: 1.282391, Train accuracy: 0.625000, val accuracy: 0.187500\n",
            "Loss: 1.030474, Train accuracy: 0.664062, val accuracy: 0.187500\n",
            "Loss: 1.282690, Train accuracy: 0.664062, val accuracy: 0.195312\n",
            "Loss: 1.388743, Train accuracy: 0.585938, val accuracy: 0.148438\n",
            "Loss: 1.094116, Train accuracy: 0.640625, val accuracy: 0.187500\n",
            "Loss: 1.013561, Train accuracy: 0.648438, val accuracy: 0.195312\n",
            "iteration 10\n",
            "Loss: 4.121265, Train accuracy: 0.164062, val accuracy: 0.093750\n",
            "Loss: 3.075692, Train accuracy: 0.164062, val accuracy: 0.195312\n",
            "Loss: 2.210285, Train accuracy: 0.164062, val accuracy: 0.140625\n",
            "Loss: 2.183647, Train accuracy: 0.171875, val accuracy: 0.109375\n",
            "Loss: 2.288894, Train accuracy: 0.187500, val accuracy: 0.203125\n",
            "Loss: 2.588169, Train accuracy: 0.250000, val accuracy: 0.132812\n",
            "Loss: 2.245487, Train accuracy: 0.265625, val accuracy: 0.117188\n",
            "Loss: 1.887095, Train accuracy: 0.265625, val accuracy: 0.109375\n",
            "Loss: 1.814252, Train accuracy: 0.273438, val accuracy: 0.132812\n",
            "Loss: 2.094479, Train accuracy: 0.257812, val accuracy: 0.125000\n",
            "Loss: 2.108373, Train accuracy: 0.265625, val accuracy: 0.148438\n",
            "Loss: 1.760367, Train accuracy: 0.257812, val accuracy: 0.164062\n",
            "Loss: 2.462572, Train accuracy: 0.289062, val accuracy: 0.132812\n",
            "Loss: 1.949017, Train accuracy: 0.320312, val accuracy: 0.164062\n",
            "Loss: 2.245750, Train accuracy: 0.304688, val accuracy: 0.195312\n",
            "Loss: 1.320499, Train accuracy: 0.328125, val accuracy: 0.171875\n",
            "Loss: 2.289832, Train accuracy: 0.328125, val accuracy: 0.179688\n",
            "Loss: 1.784825, Train accuracy: 0.367188, val accuracy: 0.179688\n",
            "Loss: 1.988677, Train accuracy: 0.351562, val accuracy: 0.179688\n",
            "Loss: 1.559137, Train accuracy: 0.382812, val accuracy: 0.179688\n",
            "Loss: 2.093603, Train accuracy: 0.359375, val accuracy: 0.156250\n",
            "Loss: 2.032192, Train accuracy: 0.367188, val accuracy: 0.171875\n",
            "Loss: 1.978330, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 2.003326, Train accuracy: 0.398438, val accuracy: 0.171875\n",
            "Loss: 2.076060, Train accuracy: 0.398438, val accuracy: 0.179688\n",
            "Loss: 1.485964, Train accuracy: 0.390625, val accuracy: 0.148438\n",
            "Loss: 2.071965, Train accuracy: 0.375000, val accuracy: 0.148438\n",
            "Loss: 1.611159, Train accuracy: 0.406250, val accuracy: 0.156250\n",
            "Loss: 1.434918, Train accuracy: 0.406250, val accuracy: 0.156250\n",
            "Loss: 1.844458, Train accuracy: 0.406250, val accuracy: 0.140625\n",
            "Loss: 1.388016, Train accuracy: 0.429688, val accuracy: 0.148438\n",
            "Loss: 1.827196, Train accuracy: 0.437500, val accuracy: 0.140625\n",
            "Loss: 2.085989, Train accuracy: 0.414062, val accuracy: 0.140625\n",
            "Loss: 1.157230, Train accuracy: 0.421875, val accuracy: 0.148438\n",
            "Loss: 1.551524, Train accuracy: 0.429688, val accuracy: 0.148438\n",
            "Loss: 1.563263, Train accuracy: 0.453125, val accuracy: 0.140625\n",
            "Loss: 2.011530, Train accuracy: 0.421875, val accuracy: 0.132812\n",
            "Loss: 1.400653, Train accuracy: 0.453125, val accuracy: 0.140625\n",
            "Loss: 1.573731, Train accuracy: 0.468750, val accuracy: 0.140625\n",
            "Loss: 1.451988, Train accuracy: 0.453125, val accuracy: 0.156250\n",
            "Loss: 1.858354, Train accuracy: 0.476562, val accuracy: 0.132812\n",
            "Loss: 1.768464, Train accuracy: 0.453125, val accuracy: 0.140625\n",
            "Loss: 1.612574, Train accuracy: 0.460938, val accuracy: 0.140625\n",
            "Loss: 1.193125, Train accuracy: 0.460938, val accuracy: 0.140625\n",
            "Loss: 1.572808, Train accuracy: 0.453125, val accuracy: 0.140625\n",
            "Loss: 1.403468, Train accuracy: 0.453125, val accuracy: 0.132812\n",
            "Loss: 1.321154, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 1.656624, Train accuracy: 0.460938, val accuracy: 0.132812\n",
            "Loss: 0.791782, Train accuracy: 0.460938, val accuracy: 0.132812\n",
            "Loss: 1.889072, Train accuracy: 0.453125, val accuracy: 0.132812\n",
            "iteration 11\n",
            "Loss: 2.582765, Train accuracy: 0.195312, val accuracy: 0.101562\n",
            "Loss: 2.669261, Train accuracy: 0.195312, val accuracy: 0.203125\n",
            "Loss: 2.464302, Train accuracy: 0.195312, val accuracy: 0.078125\n",
            "Loss: 2.155321, Train accuracy: 0.226562, val accuracy: 0.156250\n",
            "Loss: 1.960988, Train accuracy: 0.234375, val accuracy: 0.140625\n",
            "Loss: 2.106304, Train accuracy: 0.234375, val accuracy: 0.140625\n",
            "Loss: 2.115965, Train accuracy: 0.281250, val accuracy: 0.140625\n",
            "Loss: 2.033699, Train accuracy: 0.242188, val accuracy: 0.218750\n",
            "Loss: 2.090131, Train accuracy: 0.250000, val accuracy: 0.203125\n",
            "Loss: 1.845392, Train accuracy: 0.273438, val accuracy: 0.171875\n",
            "Loss: 1.764794, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 1.844433, Train accuracy: 0.343750, val accuracy: 0.179688\n",
            "Loss: 1.625519, Train accuracy: 0.375000, val accuracy: 0.203125\n",
            "Loss: 1.753263, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 1.830755, Train accuracy: 0.390625, val accuracy: 0.195312\n",
            "Loss: 1.768707, Train accuracy: 0.390625, val accuracy: 0.195312\n",
            "Loss: 1.566611, Train accuracy: 0.390625, val accuracy: 0.203125\n",
            "Loss: 1.498264, Train accuracy: 0.406250, val accuracy: 0.203125\n",
            "Loss: 1.861661, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.612834, Train accuracy: 0.406250, val accuracy: 0.187500\n",
            "Loss: 1.857447, Train accuracy: 0.406250, val accuracy: 0.187500\n",
            "Loss: 1.945784, Train accuracy: 0.414062, val accuracy: 0.187500\n",
            "Loss: 1.567698, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 1.709068, Train accuracy: 0.414062, val accuracy: 0.187500\n",
            "Loss: 1.788767, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.734682, Train accuracy: 0.429688, val accuracy: 0.179688\n",
            "Loss: 1.527280, Train accuracy: 0.429688, val accuracy: 0.179688\n",
            "Loss: 1.475984, Train accuracy: 0.445312, val accuracy: 0.179688\n",
            "Loss: 1.528822, Train accuracy: 0.460938, val accuracy: 0.187500\n",
            "Loss: 1.634850, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.608514, Train accuracy: 0.453125, val accuracy: 0.179688\n",
            "Loss: 1.617529, Train accuracy: 0.445312, val accuracy: 0.179688\n",
            "Loss: 1.664541, Train accuracy: 0.460938, val accuracy: 0.179688\n",
            "Loss: 1.351667, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.368447, Train accuracy: 0.492188, val accuracy: 0.179688\n",
            "Loss: 1.324807, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.507241, Train accuracy: 0.476562, val accuracy: 0.171875\n",
            "Loss: 1.361313, Train accuracy: 0.484375, val accuracy: 0.164062\n",
            "Loss: 1.745753, Train accuracy: 0.484375, val accuracy: 0.164062\n",
            "Loss: 1.403633, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.511155, Train accuracy: 0.476562, val accuracy: 0.164062\n",
            "Loss: 1.555286, Train accuracy: 0.500000, val accuracy: 0.164062\n",
            "Loss: 1.643355, Train accuracy: 0.492188, val accuracy: 0.164062\n",
            "Loss: 1.730264, Train accuracy: 0.500000, val accuracy: 0.171875\n",
            "Loss: 1.363553, Train accuracy: 0.500000, val accuracy: 0.171875\n",
            "Loss: 1.599785, Train accuracy: 0.507812, val accuracy: 0.164062\n",
            "Loss: 1.544637, Train accuracy: 0.484375, val accuracy: 0.156250\n",
            "Loss: 1.465410, Train accuracy: 0.515625, val accuracy: 0.156250\n",
            "Loss: 1.416382, Train accuracy: 0.507812, val accuracy: 0.164062\n",
            "Loss: 1.398753, Train accuracy: 0.507812, val accuracy: 0.156250\n",
            "iteration 12\n",
            "Loss: 3.450307, Train accuracy: 0.132812, val accuracy: 0.046875\n",
            "Loss: 2.386002, Train accuracy: 0.148438, val accuracy: 0.109375\n",
            "Loss: 2.131679, Train accuracy: 0.226562, val accuracy: 0.250000\n",
            "Loss: 2.092057, Train accuracy: 0.250000, val accuracy: 0.210938\n",
            "Loss: 2.303689, Train accuracy: 0.273438, val accuracy: 0.210938\n",
            "Loss: 2.259770, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 2.286791, Train accuracy: 0.312500, val accuracy: 0.242188\n",
            "Loss: 2.274761, Train accuracy: 0.296875, val accuracy: 0.226562\n",
            "Loss: 1.992397, Train accuracy: 0.367188, val accuracy: 0.226562\n",
            "Loss: 2.173720, Train accuracy: 0.312500, val accuracy: 0.187500\n",
            "Loss: 2.046965, Train accuracy: 0.398438, val accuracy: 0.210938\n",
            "Loss: 1.884285, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.945918, Train accuracy: 0.468750, val accuracy: 0.218750\n",
            "Loss: 1.831525, Train accuracy: 0.453125, val accuracy: 0.203125\n",
            "Loss: 1.825270, Train accuracy: 0.429688, val accuracy: 0.195312\n",
            "Loss: 1.486639, Train accuracy: 0.476562, val accuracy: 0.195312\n",
            "Loss: 1.415033, Train accuracy: 0.507812, val accuracy: 0.171875\n",
            "Loss: 1.350293, Train accuracy: 0.562500, val accuracy: 0.195312\n",
            "Loss: 1.410476, Train accuracy: 0.546875, val accuracy: 0.210938\n",
            "Loss: 1.385778, Train accuracy: 0.578125, val accuracy: 0.187500\n",
            "Loss: 1.374529, Train accuracy: 0.585938, val accuracy: 0.218750\n",
            "Loss: 1.661535, Train accuracy: 0.601562, val accuracy: 0.187500\n",
            "Loss: 1.093543, Train accuracy: 0.617188, val accuracy: 0.187500\n",
            "Loss: 1.314827, Train accuracy: 0.656250, val accuracy: 0.210938\n",
            "Loss: 1.365136, Train accuracy: 0.640625, val accuracy: 0.226562\n",
            "Loss: 1.044942, Train accuracy: 0.656250, val accuracy: 0.250000\n",
            "Loss: 0.888153, Train accuracy: 0.710938, val accuracy: 0.195312\n",
            "Loss: 0.942216, Train accuracy: 0.703125, val accuracy: 0.234375\n",
            "Loss: 1.109810, Train accuracy: 0.710938, val accuracy: 0.203125\n",
            "Loss: 0.736377, Train accuracy: 0.718750, val accuracy: 0.242188\n",
            "Loss: 0.869235, Train accuracy: 0.718750, val accuracy: 0.234375\n",
            "Loss: 1.203689, Train accuracy: 0.695312, val accuracy: 0.257812\n",
            "Loss: 1.088181, Train accuracy: 0.726562, val accuracy: 0.242188\n",
            "Loss: 1.910617, Train accuracy: 0.734375, val accuracy: 0.257812\n",
            "Loss: 0.790489, Train accuracy: 0.781250, val accuracy: 0.210938\n",
            "Loss: 1.256195, Train accuracy: 0.773438, val accuracy: 0.250000\n",
            "Loss: 1.357206, Train accuracy: 0.789062, val accuracy: 0.250000\n",
            "Loss: 0.831149, Train accuracy: 0.750000, val accuracy: 0.234375\n",
            "Loss: 0.841685, Train accuracy: 0.812500, val accuracy: 0.234375\n",
            "Loss: 0.686170, Train accuracy: 0.820312, val accuracy: 0.210938\n",
            "Loss: 0.474194, Train accuracy: 0.820312, val accuracy: 0.210938\n",
            "Loss: 0.707399, Train accuracy: 0.773438, val accuracy: 0.250000\n",
            "Loss: 0.576702, Train accuracy: 0.859375, val accuracy: 0.179688\n",
            "Loss: 0.474318, Train accuracy: 0.851562, val accuracy: 0.226562\n",
            "Loss: 0.605952, Train accuracy: 0.789062, val accuracy: 0.164062\n",
            "Loss: 0.653867, Train accuracy: 0.875000, val accuracy: 0.203125\n",
            "Loss: 0.699614, Train accuracy: 0.820312, val accuracy: 0.257812\n",
            "Loss: 0.292569, Train accuracy: 0.859375, val accuracy: 0.187500\n",
            "Loss: 1.091417, Train accuracy: 0.906250, val accuracy: 0.210938\n",
            "Loss: 0.497959, Train accuracy: 0.921875, val accuracy: 0.210938\n",
            "iteration 13\n",
            "Loss: 19.319668, Train accuracy: 0.085938, val accuracy: 0.171875\n",
            "Loss: 2.832647, Train accuracy: 0.140625, val accuracy: 0.148438\n",
            "Loss: 2.586162, Train accuracy: 0.117188, val accuracy: 0.078125\n",
            "Loss: 2.357515, Train accuracy: 0.171875, val accuracy: 0.250000\n",
            "Loss: 2.226796, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.362449, Train accuracy: 0.179688, val accuracy: 0.242188\n",
            "Loss: 2.205012, Train accuracy: 0.179688, val accuracy: 0.242188\n",
            "Loss: 2.279225, Train accuracy: 0.179688, val accuracy: 0.242188\n",
            "Loss: 2.201393, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.119425, Train accuracy: 0.179688, val accuracy: 0.242188\n",
            "Loss: 2.131356, Train accuracy: 0.195312, val accuracy: 0.250000\n",
            "Loss: 1.993724, Train accuracy: 0.195312, val accuracy: 0.257812\n",
            "Loss: 2.146119, Train accuracy: 0.203125, val accuracy: 0.257812\n",
            "Loss: 2.133444, Train accuracy: 0.218750, val accuracy: 0.250000\n",
            "Loss: 2.262402, Train accuracy: 0.234375, val accuracy: 0.234375\n",
            "Loss: 2.223745, Train accuracy: 0.218750, val accuracy: 0.265625\n",
            "Loss: 2.185613, Train accuracy: 0.242188, val accuracy: 0.242188\n",
            "Loss: 2.157386, Train accuracy: 0.265625, val accuracy: 0.226562\n",
            "Loss: 2.023661, Train accuracy: 0.242188, val accuracy: 0.250000\n",
            "Loss: 2.088213, Train accuracy: 0.242188, val accuracy: 0.242188\n",
            "Loss: 2.129714, Train accuracy: 0.250000, val accuracy: 0.250000\n",
            "Loss: 2.006371, Train accuracy: 0.242188, val accuracy: 0.210938\n",
            "Loss: 1.899868, Train accuracy: 0.234375, val accuracy: 0.210938\n",
            "Loss: 2.146968, Train accuracy: 0.250000, val accuracy: 0.265625\n",
            "Loss: 2.088188, Train accuracy: 0.242188, val accuracy: 0.234375\n",
            "Loss: 1.982942, Train accuracy: 0.250000, val accuracy: 0.234375\n",
            "Loss: 1.899116, Train accuracy: 0.265625, val accuracy: 0.234375\n",
            "Loss: 1.905781, Train accuracy: 0.250000, val accuracy: 0.226562\n",
            "Loss: 1.971799, Train accuracy: 0.250000, val accuracy: 0.195312\n",
            "Loss: 2.012079, Train accuracy: 0.250000, val accuracy: 0.234375\n",
            "Loss: 2.064646, Train accuracy: 0.242188, val accuracy: 0.234375\n",
            "Loss: 1.895011, Train accuracy: 0.257812, val accuracy: 0.218750\n",
            "Loss: 2.229692, Train accuracy: 0.257812, val accuracy: 0.218750\n",
            "Loss: 2.046454, Train accuracy: 0.265625, val accuracy: 0.210938\n",
            "Loss: 2.154860, Train accuracy: 0.257812, val accuracy: 0.226562\n",
            "Loss: 1.954790, Train accuracy: 0.242188, val accuracy: 0.218750\n",
            "Loss: 2.110067, Train accuracy: 0.265625, val accuracy: 0.195312\n",
            "Loss: 2.014829, Train accuracy: 0.296875, val accuracy: 0.195312\n",
            "Loss: 1.791779, Train accuracy: 0.281250, val accuracy: 0.179688\n",
            "Loss: 1.928808, Train accuracy: 0.281250, val accuracy: 0.179688\n",
            "Loss: 1.716844, Train accuracy: 0.312500, val accuracy: 0.179688\n",
            "Loss: 2.146689, Train accuracy: 0.320312, val accuracy: 0.179688\n",
            "Loss: 1.760797, Train accuracy: 0.320312, val accuracy: 0.156250\n",
            "Loss: 1.883154, Train accuracy: 0.265625, val accuracy: 0.164062\n",
            "Loss: 1.998618, Train accuracy: 0.320312, val accuracy: 0.226562\n",
            "Loss: 1.883358, Train accuracy: 0.343750, val accuracy: 0.187500\n",
            "Loss: 1.929768, Train accuracy: 0.289062, val accuracy: 0.148438\n",
            "Loss: 2.251458, Train accuracy: 0.343750, val accuracy: 0.164062\n",
            "Loss: 2.048336, Train accuracy: 0.296875, val accuracy: 0.164062\n",
            "Loss: 1.851777, Train accuracy: 0.335938, val accuracy: 0.179688\n",
            "iteration 14\n",
            "Loss: 4.020825, Train accuracy: 0.101562, val accuracy: 0.085938\n",
            "Loss: 1.876749, Train accuracy: 0.132812, val accuracy: 0.156250\n",
            "Loss: 2.218530, Train accuracy: 0.164062, val accuracy: 0.164062\n",
            "Loss: 2.311448, Train accuracy: 0.171875, val accuracy: 0.179688\n",
            "Loss: 2.213568, Train accuracy: 0.195312, val accuracy: 0.234375\n",
            "Loss: 2.389457, Train accuracy: 0.210938, val accuracy: 0.226562\n",
            "Loss: 2.218695, Train accuracy: 0.187500, val accuracy: 0.250000\n",
            "Loss: 2.176718, Train accuracy: 0.203125, val accuracy: 0.226562\n",
            "Loss: 2.055091, Train accuracy: 0.195312, val accuracy: 0.226562\n",
            "Loss: 2.254417, Train accuracy: 0.218750, val accuracy: 0.226562\n",
            "Loss: 2.204563, Train accuracy: 0.218750, val accuracy: 0.226562\n",
            "Loss: 2.096925, Train accuracy: 0.234375, val accuracy: 0.226562\n",
            "Loss: 2.165499, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 1.745869, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 1.763398, Train accuracy: 0.265625, val accuracy: 0.210938\n",
            "Loss: 1.656025, Train accuracy: 0.281250, val accuracy: 0.210938\n",
            "Loss: 2.148151, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 1.918076, Train accuracy: 0.273438, val accuracy: 0.234375\n",
            "Loss: 2.064767, Train accuracy: 0.289062, val accuracy: 0.218750\n",
            "Loss: 1.986252, Train accuracy: 0.296875, val accuracy: 0.210938\n",
            "Loss: 1.815446, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 2.185245, Train accuracy: 0.289062, val accuracy: 0.203125\n",
            "Loss: 1.962873, Train accuracy: 0.304688, val accuracy: 0.210938\n",
            "Loss: 2.210529, Train accuracy: 0.304688, val accuracy: 0.210938\n",
            "Loss: 2.218380, Train accuracy: 0.312500, val accuracy: 0.234375\n",
            "Loss: 1.925184, Train accuracy: 0.328125, val accuracy: 0.218750\n",
            "Loss: 1.745233, Train accuracy: 0.328125, val accuracy: 0.210938\n",
            "Loss: 1.649071, Train accuracy: 0.335938, val accuracy: 0.203125\n",
            "Loss: 2.059134, Train accuracy: 0.343750, val accuracy: 0.210938\n",
            "Loss: 1.940039, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 1.951662, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.604322, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 1.855280, Train accuracy: 0.328125, val accuracy: 0.218750\n",
            "Loss: 2.127837, Train accuracy: 0.335938, val accuracy: 0.210938\n",
            "Loss: 1.706981, Train accuracy: 0.343750, val accuracy: 0.234375\n",
            "Loss: 1.888061, Train accuracy: 0.343750, val accuracy: 0.218750\n",
            "Loss: 2.058884, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.096241, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.088526, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.904245, Train accuracy: 0.335938, val accuracy: 0.234375\n",
            "Loss: 1.805348, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 1.920357, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.221004, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.195804, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.862518, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 2.310248, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.098900, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.996309, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 1.637873, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.279051, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "iteration 15\n",
            "Loss: 14.158585, Train accuracy: 0.132812, val accuracy: 0.070312\n",
            "Loss: 3.683309, Train accuracy: 0.164062, val accuracy: 0.132812\n",
            "Loss: 3.014107, Train accuracy: 0.109375, val accuracy: 0.078125\n",
            "Loss: 2.425788, Train accuracy: 0.187500, val accuracy: 0.273438\n",
            "Loss: 2.184686, Train accuracy: 0.226562, val accuracy: 0.179688\n",
            "Loss: 2.126317, Train accuracy: 0.234375, val accuracy: 0.140625\n",
            "Loss: 2.123407, Train accuracy: 0.234375, val accuracy: 0.234375\n",
            "Loss: 2.199817, Train accuracy: 0.242188, val accuracy: 0.234375\n",
            "Loss: 2.079297, Train accuracy: 0.273438, val accuracy: 0.218750\n",
            "Loss: 2.077907, Train accuracy: 0.273438, val accuracy: 0.203125\n",
            "Loss: 2.090045, Train accuracy: 0.312500, val accuracy: 0.210938\n",
            "Loss: 2.167722, Train accuracy: 0.312500, val accuracy: 0.195312\n",
            "Loss: 2.124601, Train accuracy: 0.296875, val accuracy: 0.195312\n",
            "Loss: 1.971250, Train accuracy: 0.304688, val accuracy: 0.187500\n",
            "Loss: 2.091805, Train accuracy: 0.328125, val accuracy: 0.210938\n",
            "Loss: 1.864668, Train accuracy: 0.343750, val accuracy: 0.203125\n",
            "Loss: 2.054871, Train accuracy: 0.328125, val accuracy: 0.195312\n",
            "Loss: 2.016803, Train accuracy: 0.343750, val accuracy: 0.195312\n",
            "Loss: 2.196444, Train accuracy: 0.335938, val accuracy: 0.195312\n",
            "Loss: 2.167042, Train accuracy: 0.335938, val accuracy: 0.195312\n",
            "Loss: 2.096167, Train accuracy: 0.375000, val accuracy: 0.203125\n",
            "Loss: 1.766165, Train accuracy: 0.375000, val accuracy: 0.187500\n",
            "Loss: 2.053811, Train accuracy: 0.375000, val accuracy: 0.187500\n",
            "Loss: 1.852510, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 2.002455, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.916671, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 1.758941, Train accuracy: 0.390625, val accuracy: 0.210938\n",
            "Loss: 1.936727, Train accuracy: 0.375000, val accuracy: 0.203125\n",
            "Loss: 2.039242, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.939608, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 1.672667, Train accuracy: 0.406250, val accuracy: 0.203125\n",
            "Loss: 1.997784, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.865524, Train accuracy: 0.390625, val accuracy: 0.203125\n",
            "Loss: 1.704414, Train accuracy: 0.429688, val accuracy: 0.203125\n",
            "Loss: 2.074478, Train accuracy: 0.406250, val accuracy: 0.187500\n",
            "Loss: 1.662861, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.686779, Train accuracy: 0.429688, val accuracy: 0.195312\n",
            "Loss: 1.918433, Train accuracy: 0.437500, val accuracy: 0.203125\n",
            "Loss: 1.765590, Train accuracy: 0.437500, val accuracy: 0.187500\n",
            "Loss: 1.754884, Train accuracy: 0.437500, val accuracy: 0.187500\n",
            "Loss: 1.855175, Train accuracy: 0.445312, val accuracy: 0.195312\n",
            "Loss: 1.823778, Train accuracy: 0.429688, val accuracy: 0.187500\n",
            "Loss: 1.664337, Train accuracy: 0.406250, val accuracy: 0.195312\n",
            "Loss: 2.001913, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 1.811242, Train accuracy: 0.429688, val accuracy: 0.187500\n",
            "Loss: 1.583895, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.835915, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.485248, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.845323, Train accuracy: 0.429688, val accuracy: 0.179688\n",
            "Loss: 1.836409, Train accuracy: 0.429688, val accuracy: 0.195312\n",
            "iteration 16\n",
            "Loss: 2.286513, Train accuracy: 0.218750, val accuracy: 0.242188\n",
            "Loss: 2.309006, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.641980, Train accuracy: 0.187500, val accuracy: 0.234375\n",
            "Loss: 2.404160, Train accuracy: 0.226562, val accuracy: 0.218750\n",
            "Loss: 2.321035, Train accuracy: 0.218750, val accuracy: 0.164062\n",
            "Loss: 2.210456, Train accuracy: 0.210938, val accuracy: 0.234375\n",
            "Loss: 2.316227, Train accuracy: 0.257812, val accuracy: 0.187500\n",
            "Loss: 2.175711, Train accuracy: 0.210938, val accuracy: 0.164062\n",
            "Loss: 2.443570, Train accuracy: 0.234375, val accuracy: 0.234375\n",
            "Loss: 2.001793, Train accuracy: 0.226562, val accuracy: 0.156250\n",
            "Loss: 2.129578, Train accuracy: 0.250000, val accuracy: 0.242188\n",
            "Loss: 2.263425, Train accuracy: 0.281250, val accuracy: 0.179688\n",
            "Loss: 1.788139, Train accuracy: 0.273438, val accuracy: 0.171875\n",
            "Loss: 2.118488, Train accuracy: 0.234375, val accuracy: 0.156250\n",
            "Loss: 2.318727, Train accuracy: 0.281250, val accuracy: 0.218750\n",
            "Loss: 1.817881, Train accuracy: 0.296875, val accuracy: 0.218750\n",
            "Loss: 1.818697, Train accuracy: 0.281250, val accuracy: 0.171875\n",
            "Loss: 1.926613, Train accuracy: 0.289062, val accuracy: 0.234375\n",
            "Loss: 2.105740, Train accuracy: 0.289062, val accuracy: 0.171875\n",
            "Loss: 1.977518, Train accuracy: 0.289062, val accuracy: 0.164062\n",
            "Loss: 2.426717, Train accuracy: 0.242188, val accuracy: 0.171875\n",
            "Loss: 2.289141, Train accuracy: 0.289062, val accuracy: 0.171875\n",
            "Loss: 1.943732, Train accuracy: 0.273438, val accuracy: 0.171875\n",
            "Loss: 2.099875, Train accuracy: 0.351562, val accuracy: 0.140625\n",
            "Loss: 2.244049, Train accuracy: 0.375000, val accuracy: 0.203125\n",
            "Loss: 2.090875, Train accuracy: 0.320312, val accuracy: 0.171875\n",
            "Loss: 1.657231, Train accuracy: 0.328125, val accuracy: 0.187500\n",
            "Loss: 2.161258, Train accuracy: 0.320312, val accuracy: 0.164062\n",
            "Loss: 2.177646, Train accuracy: 0.359375, val accuracy: 0.187500\n",
            "Loss: 1.785148, Train accuracy: 0.335938, val accuracy: 0.171875\n",
            "Loss: 1.950879, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 1.691914, Train accuracy: 0.328125, val accuracy: 0.179688\n",
            "Loss: 1.673537, Train accuracy: 0.390625, val accuracy: 0.148438\n",
            "Loss: 1.895519, Train accuracy: 0.335938, val accuracy: 0.195312\n",
            "Loss: 1.904522, Train accuracy: 0.351562, val accuracy: 0.156250\n",
            "Loss: 1.573504, Train accuracy: 0.343750, val accuracy: 0.164062\n",
            "Loss: 2.089305, Train accuracy: 0.343750, val accuracy: 0.179688\n",
            "Loss: 2.119752, Train accuracy: 0.367188, val accuracy: 0.148438\n",
            "Loss: 2.367091, Train accuracy: 0.359375, val accuracy: 0.179688\n",
            "Loss: 2.017905, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 2.117519, Train accuracy: 0.382812, val accuracy: 0.179688\n",
            "Loss: 1.668422, Train accuracy: 0.414062, val accuracy: 0.187500\n",
            "Loss: 1.788230, Train accuracy: 0.359375, val accuracy: 0.148438\n",
            "Loss: 1.662009, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 2.040805, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.871020, Train accuracy: 0.382812, val accuracy: 0.148438\n",
            "Loss: 1.832782, Train accuracy: 0.406250, val accuracy: 0.179688\n",
            "Loss: 1.450524, Train accuracy: 0.390625, val accuracy: 0.156250\n",
            "Loss: 1.592215, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 2.213947, Train accuracy: 0.429688, val accuracy: 0.179688\n",
            "iteration 17\n",
            "Loss: 2.289000, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.092008, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.361277, Train accuracy: 0.218750, val accuracy: 0.195312\n",
            "Loss: 2.283791, Train accuracy: 0.203125, val accuracy: 0.203125\n",
            "Loss: 2.284024, Train accuracy: 0.226562, val accuracy: 0.203125\n",
            "Loss: 2.093923, Train accuracy: 0.242188, val accuracy: 0.203125\n",
            "Loss: 2.015996, Train accuracy: 0.226562, val accuracy: 0.195312\n",
            "Loss: 2.165767, Train accuracy: 0.218750, val accuracy: 0.218750\n",
            "Loss: 2.161384, Train accuracy: 0.250000, val accuracy: 0.203125\n",
            "Loss: 2.051924, Train accuracy: 0.242188, val accuracy: 0.210938\n",
            "Loss: 2.245469, Train accuracy: 0.242188, val accuracy: 0.195312\n",
            "Loss: 2.189054, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 2.386436, Train accuracy: 0.265625, val accuracy: 0.187500\n",
            "Loss: 2.069390, Train accuracy: 0.257812, val accuracy: 0.179688\n",
            "Loss: 2.077668, Train accuracy: 0.242188, val accuracy: 0.203125\n",
            "Loss: 1.996005, Train accuracy: 0.234375, val accuracy: 0.203125\n",
            "Loss: 2.170626, Train accuracy: 0.257812, val accuracy: 0.164062\n",
            "Loss: 1.981858, Train accuracy: 0.273438, val accuracy: 0.195312\n",
            "Loss: 2.279011, Train accuracy: 0.242188, val accuracy: 0.210938\n",
            "Loss: 1.923930, Train accuracy: 0.250000, val accuracy: 0.171875\n",
            "Loss: 2.103241, Train accuracy: 0.265625, val accuracy: 0.179688\n",
            "Loss: 2.112160, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 1.906466, Train accuracy: 0.281250, val accuracy: 0.164062\n",
            "Loss: 2.363984, Train accuracy: 0.242188, val accuracy: 0.195312\n",
            "Loss: 1.896276, Train accuracy: 0.250000, val accuracy: 0.203125\n",
            "Loss: 1.962625, Train accuracy: 0.289062, val accuracy: 0.187500\n",
            "Loss: 2.168002, Train accuracy: 0.296875, val accuracy: 0.187500\n",
            "Loss: 2.019494, Train accuracy: 0.281250, val accuracy: 0.179688\n",
            "Loss: 2.044141, Train accuracy: 0.257812, val accuracy: 0.226562\n",
            "Loss: 2.156611, Train accuracy: 0.265625, val accuracy: 0.203125\n",
            "Loss: 2.197620, Train accuracy: 0.296875, val accuracy: 0.187500\n",
            "Loss: 2.210348, Train accuracy: 0.289062, val accuracy: 0.187500\n",
            "Loss: 2.046142, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 2.141689, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 1.892876, Train accuracy: 0.289062, val accuracy: 0.187500\n",
            "Loss: 2.050002, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 2.058339, Train accuracy: 0.296875, val accuracy: 0.187500\n",
            "Loss: 2.222263, Train accuracy: 0.296875, val accuracy: 0.187500\n",
            "Loss: 2.126677, Train accuracy: 0.304688, val accuracy: 0.203125\n",
            "Loss: 2.014858, Train accuracy: 0.289062, val accuracy: 0.171875\n",
            "Loss: 2.049923, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 2.005605, Train accuracy: 0.312500, val accuracy: 0.187500\n",
            "Loss: 2.002598, Train accuracy: 0.296875, val accuracy: 0.187500\n",
            "Loss: 2.135874, Train accuracy: 0.281250, val accuracy: 0.195312\n",
            "Loss: 2.347258, Train accuracy: 0.304688, val accuracy: 0.171875\n",
            "Loss: 2.014199, Train accuracy: 0.304688, val accuracy: 0.187500\n",
            "Loss: 2.088619, Train accuracy: 0.312500, val accuracy: 0.218750\n",
            "Loss: 2.175059, Train accuracy: 0.320312, val accuracy: 0.179688\n",
            "Loss: 1.591297, Train accuracy: 0.304688, val accuracy: 0.171875\n",
            "Loss: 1.969966, Train accuracy: 0.296875, val accuracy: 0.171875\n",
            "iteration 18\n",
            "Loss: 2.102716, Train accuracy: 0.132812, val accuracy: 0.093750\n",
            "Loss: 2.696250, Train accuracy: 0.085938, val accuracy: 0.156250\n",
            "Loss: 2.506965, Train accuracy: 0.156250, val accuracy: 0.078125\n",
            "Loss: 2.929656, Train accuracy: 0.234375, val accuracy: 0.187500\n",
            "Loss: 2.525108, Train accuracy: 0.187500, val accuracy: 0.242188\n",
            "Loss: 2.174958, Train accuracy: 0.203125, val accuracy: 0.109375\n",
            "Loss: 2.082237, Train accuracy: 0.265625, val accuracy: 0.140625\n",
            "Loss: 2.226037, Train accuracy: 0.265625, val accuracy: 0.070312\n",
            "Loss: 1.821593, Train accuracy: 0.242188, val accuracy: 0.187500\n",
            "Loss: 2.098895, Train accuracy: 0.289062, val accuracy: 0.101562\n",
            "Loss: 2.559905, Train accuracy: 0.210938, val accuracy: 0.101562\n",
            "Loss: 2.462597, Train accuracy: 0.242188, val accuracy: 0.210938\n",
            "Loss: 2.380604, Train accuracy: 0.273438, val accuracy: 0.148438\n",
            "Loss: 2.271429, Train accuracy: 0.312500, val accuracy: 0.125000\n",
            "Loss: 2.630783, Train accuracy: 0.257812, val accuracy: 0.179688\n",
            "Loss: 2.223323, Train accuracy: 0.312500, val accuracy: 0.148438\n",
            "Loss: 2.015281, Train accuracy: 0.320312, val accuracy: 0.132812\n",
            "Loss: 2.073248, Train accuracy: 0.257812, val accuracy: 0.171875\n",
            "Loss: 2.301961, Train accuracy: 0.320312, val accuracy: 0.117188\n",
            "Loss: 2.185926, Train accuracy: 0.273438, val accuracy: 0.101562\n",
            "Loss: 2.266679, Train accuracy: 0.273438, val accuracy: 0.156250\n",
            "Loss: 2.428568, Train accuracy: 0.250000, val accuracy: 0.101562\n",
            "Loss: 2.285359, Train accuracy: 0.320312, val accuracy: 0.148438\n",
            "Loss: 1.979385, Train accuracy: 0.312500, val accuracy: 0.117188\n",
            "Loss: 2.161720, Train accuracy: 0.304688, val accuracy: 0.132812\n",
            "Loss: 1.954952, Train accuracy: 0.257812, val accuracy: 0.148438\n",
            "Loss: 2.409552, Train accuracy: 0.304688, val accuracy: 0.109375\n",
            "Loss: 2.282211, Train accuracy: 0.273438, val accuracy: 0.109375\n",
            "Loss: 2.159965, Train accuracy: 0.289062, val accuracy: 0.148438\n",
            "Loss: 2.327000, Train accuracy: 0.281250, val accuracy: 0.125000\n",
            "Loss: 2.230062, Train accuracy: 0.335938, val accuracy: 0.140625\n",
            "Loss: 2.055803, Train accuracy: 0.343750, val accuracy: 0.156250\n",
            "Loss: 2.092508, Train accuracy: 0.312500, val accuracy: 0.109375\n",
            "Loss: 2.069497, Train accuracy: 0.312500, val accuracy: 0.140625\n",
            "Loss: 1.987790, Train accuracy: 0.343750, val accuracy: 0.125000\n",
            "Loss: 2.298206, Train accuracy: 0.312500, val accuracy: 0.132812\n",
            "Loss: 2.183271, Train accuracy: 0.304688, val accuracy: 0.117188\n",
            "Loss: 2.025010, Train accuracy: 0.343750, val accuracy: 0.140625\n",
            "Loss: 2.171929, Train accuracy: 0.351562, val accuracy: 0.140625\n",
            "Loss: 2.171062, Train accuracy: 0.328125, val accuracy: 0.125000\n",
            "Loss: 1.961305, Train accuracy: 0.328125, val accuracy: 0.132812\n",
            "Loss: 2.045565, Train accuracy: 0.343750, val accuracy: 0.148438\n",
            "Loss: 1.666429, Train accuracy: 0.351562, val accuracy: 0.125000\n",
            "Loss: 2.077654, Train accuracy: 0.343750, val accuracy: 0.117188\n",
            "Loss: 2.175799, Train accuracy: 0.296875, val accuracy: 0.117188\n",
            "Loss: 2.236887, Train accuracy: 0.343750, val accuracy: 0.132812\n",
            "Loss: 2.004158, Train accuracy: 0.328125, val accuracy: 0.125000\n",
            "Loss: 1.803739, Train accuracy: 0.351562, val accuracy: 0.132812\n",
            "Loss: 1.995953, Train accuracy: 0.343750, val accuracy: 0.140625\n",
            "Loss: 1.922159, Train accuracy: 0.335938, val accuracy: 0.125000\n",
            "iteration 19\n",
            "Loss: 2.199642, Train accuracy: 0.187500, val accuracy: 0.187500\n",
            "Loss: 2.186483, Train accuracy: 0.203125, val accuracy: 0.171875\n",
            "Loss: 2.355806, Train accuracy: 0.226562, val accuracy: 0.187500\n",
            "Loss: 2.269713, Train accuracy: 0.179688, val accuracy: 0.179688\n",
            "Loss: 2.225265, Train accuracy: 0.187500, val accuracy: 0.179688\n",
            "Loss: 2.214413, Train accuracy: 0.195312, val accuracy: 0.187500\n",
            "Loss: 2.016984, Train accuracy: 0.195312, val accuracy: 0.179688\n",
            "Loss: 2.119473, Train accuracy: 0.187500, val accuracy: 0.179688\n",
            "Loss: 2.171426, Train accuracy: 0.195312, val accuracy: 0.179688\n",
            "Loss: 2.069456, Train accuracy: 0.195312, val accuracy: 0.187500\n",
            "Loss: 2.269942, Train accuracy: 0.195312, val accuracy: 0.179688\n",
            "Loss: 2.105203, Train accuracy: 0.195312, val accuracy: 0.179688\n",
            "Loss: 2.171821, Train accuracy: 0.210938, val accuracy: 0.187500\n",
            "Loss: 2.023303, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.094494, Train accuracy: 0.203125, val accuracy: 0.171875\n",
            "Loss: 1.886007, Train accuracy: 0.203125, val accuracy: 0.171875\n",
            "Loss: 2.137918, Train accuracy: 0.203125, val accuracy: 0.171875\n",
            "Loss: 1.970330, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.166302, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.099063, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.202261, Train accuracy: 0.203125, val accuracy: 0.179688\n",
            "Loss: 1.999502, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.044926, Train accuracy: 0.226562, val accuracy: 0.179688\n",
            "Loss: 2.145484, Train accuracy: 0.218750, val accuracy: 0.179688\n",
            "Loss: 2.008016, Train accuracy: 0.234375, val accuracy: 0.179688\n",
            "Loss: 2.265843, Train accuracy: 0.226562, val accuracy: 0.187500\n",
            "Loss: 2.048052, Train accuracy: 0.226562, val accuracy: 0.187500\n",
            "Loss: 2.097190, Train accuracy: 0.226562, val accuracy: 0.179688\n",
            "Loss: 2.086536, Train accuracy: 0.226562, val accuracy: 0.187500\n",
            "Loss: 1.869501, Train accuracy: 0.226562, val accuracy: 0.195312\n",
            "Loss: 2.281036, Train accuracy: 0.226562, val accuracy: 0.195312\n",
            "Loss: 2.096937, Train accuracy: 0.234375, val accuracy: 0.187500\n",
            "Loss: 2.127342, Train accuracy: 0.234375, val accuracy: 0.195312\n",
            "Loss: 1.986871, Train accuracy: 0.242188, val accuracy: 0.187500\n",
            "Loss: 2.027632, Train accuracy: 0.242188, val accuracy: 0.187500\n",
            "Loss: 2.062226, Train accuracy: 0.234375, val accuracy: 0.187500\n",
            "Loss: 2.051496, Train accuracy: 0.234375, val accuracy: 0.187500\n",
            "Loss: 2.094035, Train accuracy: 0.234375, val accuracy: 0.195312\n",
            "Loss: 1.848020, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 2.033864, Train accuracy: 0.250000, val accuracy: 0.187500\n",
            "Loss: 2.193202, Train accuracy: 0.242188, val accuracy: 0.187500\n",
            "Loss: 2.058053, Train accuracy: 0.265625, val accuracy: 0.195312\n",
            "Loss: 1.962700, Train accuracy: 0.257812, val accuracy: 0.203125\n",
            "Loss: 2.204892, Train accuracy: 0.250000, val accuracy: 0.195312\n",
            "Loss: 1.948650, Train accuracy: 0.257812, val accuracy: 0.195312\n",
            "Loss: 1.947352, Train accuracy: 0.265625, val accuracy: 0.179688\n",
            "Loss: 2.090303, Train accuracy: 0.257812, val accuracy: 0.187500\n",
            "Loss: 2.040046, Train accuracy: 0.250000, val accuracy: 0.187500\n",
            "Loss: 1.932124, Train accuracy: 0.265625, val accuracy: 0.195312\n",
            "Loss: 1.945916, Train accuracy: 0.265625, val accuracy: 0.187500\n",
            "iteration 20\n",
            "Loss: 2.171818, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.030019, Train accuracy: 0.210938, val accuracy: 0.242188\n",
            "Loss: 2.056274, Train accuracy: 0.187500, val accuracy: 0.250000\n",
            "Loss: 2.081629, Train accuracy: 0.250000, val accuracy: 0.195312\n",
            "Loss: 2.226348, Train accuracy: 0.296875, val accuracy: 0.171875\n",
            "Loss: 2.081262, Train accuracy: 0.257812, val accuracy: 0.179688\n",
            "Loss: 2.305296, Train accuracy: 0.257812, val accuracy: 0.234375\n",
            "Loss: 2.430409, Train accuracy: 0.257812, val accuracy: 0.179688\n",
            "Loss: 2.064609, Train accuracy: 0.250000, val accuracy: 0.226562\n",
            "Loss: 1.950233, Train accuracy: 0.281250, val accuracy: 0.187500\n",
            "Loss: 2.034538, Train accuracy: 0.289062, val accuracy: 0.226562\n",
            "Loss: 2.068006, Train accuracy: 0.343750, val accuracy: 0.171875\n",
            "Loss: 2.255265, Train accuracy: 0.296875, val accuracy: 0.164062\n",
            "Loss: 2.153406, Train accuracy: 0.312500, val accuracy: 0.210938\n",
            "Loss: 2.073816, Train accuracy: 0.328125, val accuracy: 0.156250\n",
            "Loss: 1.640814, Train accuracy: 0.328125, val accuracy: 0.203125\n",
            "Loss: 2.212344, Train accuracy: 0.359375, val accuracy: 0.171875\n",
            "Loss: 1.881050, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 2.035786, Train accuracy: 0.296875, val accuracy: 0.179688\n",
            "Loss: 2.055193, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 2.143700, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 1.610251, Train accuracy: 0.398438, val accuracy: 0.187500\n",
            "Loss: 1.683468, Train accuracy: 0.414062, val accuracy: 0.195312\n",
            "Loss: 1.743572, Train accuracy: 0.414062, val accuracy: 0.187500\n",
            "Loss: 1.846925, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 2.082353, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.700761, Train accuracy: 0.453125, val accuracy: 0.195312\n",
            "Loss: 1.625422, Train accuracy: 0.437500, val accuracy: 0.195312\n",
            "Loss: 1.968039, Train accuracy: 0.453125, val accuracy: 0.179688\n",
            "Loss: 1.888432, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.772435, Train accuracy: 0.492188, val accuracy: 0.195312\n",
            "Loss: 1.938352, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.516983, Train accuracy: 0.484375, val accuracy: 0.187500\n",
            "Loss: 1.635480, Train accuracy: 0.414062, val accuracy: 0.195312\n",
            "Loss: 1.694841, Train accuracy: 0.484375, val accuracy: 0.187500\n",
            "Loss: 1.539630, Train accuracy: 0.437500, val accuracy: 0.171875\n",
            "Loss: 1.592554, Train accuracy: 0.507812, val accuracy: 0.179688\n",
            "Loss: 1.866812, Train accuracy: 0.484375, val accuracy: 0.187500\n",
            "Loss: 1.708336, Train accuracy: 0.468750, val accuracy: 0.171875\n",
            "Loss: 1.796866, Train accuracy: 0.500000, val accuracy: 0.195312\n",
            "Loss: 1.659406, Train accuracy: 0.476562, val accuracy: 0.179688\n",
            "Loss: 1.243791, Train accuracy: 0.492188, val accuracy: 0.171875\n",
            "Loss: 1.669857, Train accuracy: 0.500000, val accuracy: 0.187500\n",
            "Loss: 1.847106, Train accuracy: 0.507812, val accuracy: 0.171875\n",
            "Loss: 2.037173, Train accuracy: 0.523438, val accuracy: 0.171875\n",
            "Loss: 1.909808, Train accuracy: 0.515625, val accuracy: 0.187500\n",
            "Loss: 1.238249, Train accuracy: 0.539062, val accuracy: 0.187500\n",
            "Loss: 1.413586, Train accuracy: 0.523438, val accuracy: 0.195312\n",
            "Loss: 1.513760, Train accuracy: 0.593750, val accuracy: 0.187500\n",
            "Loss: 2.060311, Train accuracy: 0.539062, val accuracy: 0.210938\n",
            "iteration 21\n",
            "Loss: 2.272801, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.576002, Train accuracy: 0.250000, val accuracy: 0.171875\n",
            "Loss: 2.629153, Train accuracy: 0.210938, val accuracy: 0.187500\n",
            "Loss: 2.384100, Train accuracy: 0.234375, val accuracy: 0.187500\n",
            "Loss: 2.164543, Train accuracy: 0.234375, val accuracy: 0.179688\n",
            "Loss: 2.258310, Train accuracy: 0.218750, val accuracy: 0.078125\n",
            "Loss: 2.103031, Train accuracy: 0.242188, val accuracy: 0.156250\n",
            "Loss: 2.088263, Train accuracy: 0.250000, val accuracy: 0.171875\n",
            "Loss: 2.230555, Train accuracy: 0.265625, val accuracy: 0.203125\n",
            "Loss: 2.468584, Train accuracy: 0.289062, val accuracy: 0.101562\n",
            "Loss: 2.243202, Train accuracy: 0.312500, val accuracy: 0.140625\n",
            "Loss: 1.999809, Train accuracy: 0.304688, val accuracy: 0.093750\n",
            "Loss: 2.133534, Train accuracy: 0.320312, val accuracy: 0.187500\n",
            "Loss: 2.242340, Train accuracy: 0.414062, val accuracy: 0.109375\n",
            "Loss: 1.967108, Train accuracy: 0.343750, val accuracy: 0.125000\n",
            "Loss: 2.388998, Train accuracy: 0.335938, val accuracy: 0.148438\n",
            "Loss: 2.138605, Train accuracy: 0.218750, val accuracy: 0.101562\n",
            "Loss: 2.306105, Train accuracy: 0.375000, val accuracy: 0.179688\n",
            "Loss: 1.966696, Train accuracy: 0.320312, val accuracy: 0.093750\n",
            "Loss: 2.176283, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 2.003839, Train accuracy: 0.382812, val accuracy: 0.101562\n",
            "Loss: 1.907497, Train accuracy: 0.390625, val accuracy: 0.156250\n",
            "Loss: 2.003323, Train accuracy: 0.359375, val accuracy: 0.101562\n",
            "Loss: 1.795211, Train accuracy: 0.343750, val accuracy: 0.179688\n",
            "Loss: 2.117796, Train accuracy: 0.398438, val accuracy: 0.140625\n",
            "Loss: 1.946584, Train accuracy: 0.367188, val accuracy: 0.125000\n",
            "Loss: 1.862337, Train accuracy: 0.421875, val accuracy: 0.156250\n",
            "Loss: 1.713498, Train accuracy: 0.429688, val accuracy: 0.093750\n",
            "Loss: 1.889837, Train accuracy: 0.414062, val accuracy: 0.164062\n",
            "Loss: 1.917732, Train accuracy: 0.406250, val accuracy: 0.148438\n",
            "Loss: 2.109200, Train accuracy: 0.414062, val accuracy: 0.125000\n",
            "Loss: 2.205947, Train accuracy: 0.429688, val accuracy: 0.148438\n",
            "Loss: 1.841501, Train accuracy: 0.414062, val accuracy: 0.109375\n",
            "Loss: 1.738207, Train accuracy: 0.445312, val accuracy: 0.140625\n",
            "Loss: 1.885354, Train accuracy: 0.453125, val accuracy: 0.156250\n",
            "Loss: 1.745888, Train accuracy: 0.445312, val accuracy: 0.148438\n",
            "Loss: 1.788133, Train accuracy: 0.460938, val accuracy: 0.140625\n",
            "Loss: 1.823814, Train accuracy: 0.421875, val accuracy: 0.148438\n",
            "Loss: 1.749529, Train accuracy: 0.484375, val accuracy: 0.109375\n",
            "Loss: 1.652024, Train accuracy: 0.476562, val accuracy: 0.195312\n",
            "Loss: 1.963137, Train accuracy: 0.445312, val accuracy: 0.117188\n",
            "Loss: 1.888719, Train accuracy: 0.468750, val accuracy: 0.101562\n",
            "Loss: 1.897114, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.837055, Train accuracy: 0.468750, val accuracy: 0.140625\n",
            "Loss: 1.713435, Train accuracy: 0.484375, val accuracy: 0.093750\n",
            "Loss: 1.840778, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.842817, Train accuracy: 0.484375, val accuracy: 0.125000\n",
            "Loss: 1.560666, Train accuracy: 0.492188, val accuracy: 0.156250\n",
            "Loss: 1.955500, Train accuracy: 0.445312, val accuracy: 0.171875\n",
            "Loss: 1.798118, Train accuracy: 0.476562, val accuracy: 0.109375\n",
            "iteration 22\n",
            "Loss: 2.319352, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.445888, Train accuracy: 0.187500, val accuracy: 0.148438\n",
            "Loss: 2.495482, Train accuracy: 0.210938, val accuracy: 0.234375\n",
            "Loss: 2.412685, Train accuracy: 0.226562, val accuracy: 0.250000\n",
            "Loss: 2.194034, Train accuracy: 0.203125, val accuracy: 0.117188\n",
            "Loss: 2.575356, Train accuracy: 0.226562, val accuracy: 0.234375\n",
            "Loss: 2.183230, Train accuracy: 0.210938, val accuracy: 0.218750\n",
            "Loss: 2.148509, Train accuracy: 0.265625, val accuracy: 0.234375\n",
            "Loss: 2.010403, Train accuracy: 0.257812, val accuracy: 0.210938\n",
            "Loss: 2.118198, Train accuracy: 0.273438, val accuracy: 0.242188\n",
            "Loss: 2.235661, Train accuracy: 0.265625, val accuracy: 0.218750\n",
            "Loss: 1.884836, Train accuracy: 0.335938, val accuracy: 0.203125\n",
            "Loss: 1.592730, Train accuracy: 0.320312, val accuracy: 0.187500\n",
            "Loss: 1.904864, Train accuracy: 0.257812, val accuracy: 0.226562\n",
            "Loss: 1.550310, Train accuracy: 0.343750, val accuracy: 0.187500\n",
            "Loss: 1.744980, Train accuracy: 0.351562, val accuracy: 0.218750\n",
            "Loss: 1.947575, Train accuracy: 0.351562, val accuracy: 0.203125\n",
            "Loss: 1.805875, Train accuracy: 0.343750, val accuracy: 0.203125\n",
            "Loss: 1.822522, Train accuracy: 0.343750, val accuracy: 0.218750\n",
            "Loss: 1.961438, Train accuracy: 0.398438, val accuracy: 0.203125\n",
            "Loss: 1.676072, Train accuracy: 0.359375, val accuracy: 0.210938\n",
            "Loss: 2.149318, Train accuracy: 0.359375, val accuracy: 0.218750\n",
            "Loss: 1.985288, Train accuracy: 0.351562, val accuracy: 0.210938\n",
            "Loss: 1.653814, Train accuracy: 0.390625, val accuracy: 0.203125\n",
            "Loss: 2.317983, Train accuracy: 0.351562, val accuracy: 0.203125\n",
            "Loss: 1.770271, Train accuracy: 0.382812, val accuracy: 0.226562\n",
            "Loss: 1.732613, Train accuracy: 0.375000, val accuracy: 0.218750\n",
            "Loss: 2.111176, Train accuracy: 0.367188, val accuracy: 0.226562\n",
            "Loss: 1.739629, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 1.788009, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 1.624063, Train accuracy: 0.414062, val accuracy: 0.218750\n",
            "Loss: 1.747784, Train accuracy: 0.390625, val accuracy: 0.210938\n",
            "Loss: 1.859276, Train accuracy: 0.382812, val accuracy: 0.203125\n",
            "Loss: 1.701098, Train accuracy: 0.398438, val accuracy: 0.210938\n",
            "Loss: 2.128189, Train accuracy: 0.390625, val accuracy: 0.195312\n",
            "Loss: 1.902023, Train accuracy: 0.398438, val accuracy: 0.210938\n",
            "Loss: 1.713995, Train accuracy: 0.421875, val accuracy: 0.210938\n",
            "Loss: 1.699577, Train accuracy: 0.398438, val accuracy: 0.187500\n",
            "Loss: 2.125490, Train accuracy: 0.382812, val accuracy: 0.203125\n",
            "Loss: 1.630986, Train accuracy: 0.406250, val accuracy: 0.210938\n",
            "Loss: 1.829489, Train accuracy: 0.421875, val accuracy: 0.210938\n",
            "Loss: 2.287416, Train accuracy: 0.406250, val accuracy: 0.187500\n",
            "Loss: 1.899216, Train accuracy: 0.445312, val accuracy: 0.203125\n",
            "Loss: 2.023741, Train accuracy: 0.390625, val accuracy: 0.187500\n",
            "Loss: 1.665343, Train accuracy: 0.406250, val accuracy: 0.195312\n",
            "Loss: 2.035789, Train accuracy: 0.429688, val accuracy: 0.187500\n",
            "Loss: 1.635578, Train accuracy: 0.406250, val accuracy: 0.195312\n",
            "Loss: 2.135777, Train accuracy: 0.398438, val accuracy: 0.203125\n",
            "Loss: 2.034512, Train accuracy: 0.437500, val accuracy: 0.203125\n",
            "Loss: 1.825359, Train accuracy: 0.429688, val accuracy: 0.203125\n",
            "iteration 23\n",
            "Loss: 2.483598, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.425391, Train accuracy: 0.203125, val accuracy: 0.195312\n",
            "Loss: 2.153799, Train accuracy: 0.140625, val accuracy: 0.093750\n",
            "Loss: 2.358270, Train accuracy: 0.257812, val accuracy: 0.210938\n",
            "Loss: 2.324359, Train accuracy: 0.257812, val accuracy: 0.242188\n",
            "Loss: 2.276879, Train accuracy: 0.312500, val accuracy: 0.085938\n",
            "Loss: 2.026272, Train accuracy: 0.320312, val accuracy: 0.187500\n",
            "Loss: 2.023447, Train accuracy: 0.320312, val accuracy: 0.218750\n",
            "Loss: 2.053700, Train accuracy: 0.343750, val accuracy: 0.085938\n",
            "Loss: 1.935264, Train accuracy: 0.351562, val accuracy: 0.164062\n",
            "Loss: 2.132075, Train accuracy: 0.328125, val accuracy: 0.179688\n",
            "Loss: 1.977480, Train accuracy: 0.367188, val accuracy: 0.164062\n",
            "Loss: 1.998218, Train accuracy: 0.367188, val accuracy: 0.132812\n",
            "Loss: 1.927692, Train accuracy: 0.398438, val accuracy: 0.140625\n",
            "Loss: 1.975310, Train accuracy: 0.351562, val accuracy: 0.187500\n",
            "Loss: 2.112660, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.952145, Train accuracy: 0.382812, val accuracy: 0.101562\n",
            "Loss: 1.870787, Train accuracy: 0.382812, val accuracy: 0.210938\n",
            "Loss: 1.777472, Train accuracy: 0.375000, val accuracy: 0.148438\n",
            "Loss: 1.881639, Train accuracy: 0.367188, val accuracy: 0.203125\n",
            "Loss: 2.018779, Train accuracy: 0.375000, val accuracy: 0.179688\n",
            "Loss: 1.821902, Train accuracy: 0.421875, val accuracy: 0.125000\n",
            "Loss: 2.400348, Train accuracy: 0.390625, val accuracy: 0.132812\n",
            "Loss: 2.001780, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.957515, Train accuracy: 0.414062, val accuracy: 0.132812\n",
            "Loss: 2.059882, Train accuracy: 0.406250, val accuracy: 0.179688\n",
            "Loss: 1.792913, Train accuracy: 0.421875, val accuracy: 0.203125\n",
            "Loss: 1.816452, Train accuracy: 0.375000, val accuracy: 0.171875\n",
            "Loss: 1.840866, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.859966, Train accuracy: 0.421875, val accuracy: 0.171875\n",
            "Loss: 1.759603, Train accuracy: 0.421875, val accuracy: 0.140625\n",
            "Loss: 1.697460, Train accuracy: 0.390625, val accuracy: 0.187500\n",
            "Loss: 1.962193, Train accuracy: 0.421875, val accuracy: 0.203125\n",
            "Loss: 1.779104, Train accuracy: 0.437500, val accuracy: 0.171875\n",
            "Loss: 1.757704, Train accuracy: 0.421875, val accuracy: 0.148438\n",
            "Loss: 1.935387, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.721779, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 1.680098, Train accuracy: 0.414062, val accuracy: 0.171875\n",
            "Loss: 2.023849, Train accuracy: 0.421875, val accuracy: 0.148438\n",
            "Loss: 1.793552, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.838847, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.828412, Train accuracy: 0.421875, val accuracy: 0.164062\n",
            "Loss: 1.711777, Train accuracy: 0.429688, val accuracy: 0.148438\n",
            "Loss: 1.875356, Train accuracy: 0.453125, val accuracy: 0.164062\n",
            "Loss: 1.542088, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 1.915102, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 1.519598, Train accuracy: 0.421875, val accuracy: 0.171875\n",
            "Loss: 1.461467, Train accuracy: 0.429688, val accuracy: 0.156250\n",
            "Loss: 1.689449, Train accuracy: 0.421875, val accuracy: 0.156250\n",
            "Loss: 1.957198, Train accuracy: 0.421875, val accuracy: 0.171875\n",
            "iteration 24\n",
            "Loss: 2.409377, Train accuracy: 0.140625, val accuracy: 0.085938\n",
            "Loss: 2.301404, Train accuracy: 0.210938, val accuracy: 0.257812\n",
            "Loss: 1.996808, Train accuracy: 0.195312, val accuracy: 0.250000\n",
            "Loss: 2.221610, Train accuracy: 0.171875, val accuracy: 0.078125\n",
            "Loss: 2.453663, Train accuracy: 0.203125, val accuracy: 0.257812\n",
            "Loss: 2.386451, Train accuracy: 0.242188, val accuracy: 0.164062\n",
            "Loss: 2.369321, Train accuracy: 0.320312, val accuracy: 0.156250\n",
            "Loss: 2.043376, Train accuracy: 0.328125, val accuracy: 0.203125\n",
            "Loss: 1.741922, Train accuracy: 0.304688, val accuracy: 0.226562\n",
            "Loss: 2.136351, Train accuracy: 0.281250, val accuracy: 0.210938\n",
            "Loss: 1.635372, Train accuracy: 0.320312, val accuracy: 0.179688\n",
            "Loss: 2.209009, Train accuracy: 0.289062, val accuracy: 0.203125\n",
            "Loss: 2.076688, Train accuracy: 0.359375, val accuracy: 0.156250\n",
            "Loss: 1.665419, Train accuracy: 0.304688, val accuracy: 0.164062\n",
            "Loss: 2.000621, Train accuracy: 0.328125, val accuracy: 0.226562\n",
            "Loss: 1.454487, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 1.923726, Train accuracy: 0.429688, val accuracy: 0.164062\n",
            "Loss: 1.929403, Train accuracy: 0.437500, val accuracy: 0.171875\n",
            "Loss: 2.174222, Train accuracy: 0.351562, val accuracy: 0.093750\n",
            "Loss: 1.825498, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 1.816056, Train accuracy: 0.375000, val accuracy: 0.179688\n",
            "Loss: 2.069148, Train accuracy: 0.375000, val accuracy: 0.195312\n",
            "Loss: 1.762154, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 1.578435, Train accuracy: 0.429688, val accuracy: 0.171875\n",
            "Loss: 1.939606, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 1.395132, Train accuracy: 0.390625, val accuracy: 0.171875\n",
            "Loss: 1.839549, Train accuracy: 0.359375, val accuracy: 0.218750\n",
            "Loss: 1.605875, Train accuracy: 0.453125, val accuracy: 0.156250\n",
            "Loss: 1.585463, Train accuracy: 0.445312, val accuracy: 0.148438\n",
            "Loss: 1.546949, Train accuracy: 0.468750, val accuracy: 0.148438\n",
            "Loss: 1.426870, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.604323, Train accuracy: 0.460938, val accuracy: 0.156250\n",
            "Loss: 2.132715, Train accuracy: 0.453125, val accuracy: 0.171875\n",
            "Loss: 1.981482, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.630944, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 1.512902, Train accuracy: 0.492188, val accuracy: 0.156250\n",
            "Loss: 1.737449, Train accuracy: 0.468750, val accuracy: 0.148438\n",
            "Loss: 1.718593, Train accuracy: 0.453125, val accuracy: 0.164062\n",
            "Loss: 1.220979, Train accuracy: 0.437500, val accuracy: 0.148438\n",
            "Loss: 1.748466, Train accuracy: 0.476562, val accuracy: 0.148438\n",
            "Loss: 1.496640, Train accuracy: 0.468750, val accuracy: 0.179688\n",
            "Loss: 1.590489, Train accuracy: 0.476562, val accuracy: 0.156250\n",
            "Loss: 1.305895, Train accuracy: 0.492188, val accuracy: 0.148438\n",
            "Loss: 1.352549, Train accuracy: 0.468750, val accuracy: 0.156250\n",
            "Loss: 1.386796, Train accuracy: 0.468750, val accuracy: 0.164062\n",
            "Loss: 1.797405, Train accuracy: 0.476562, val accuracy: 0.156250\n",
            "Loss: 1.756587, Train accuracy: 0.484375, val accuracy: 0.156250\n",
            "Loss: 1.234969, Train accuracy: 0.500000, val accuracy: 0.148438\n",
            "Loss: 1.445116, Train accuracy: 0.484375, val accuracy: 0.171875\n",
            "Loss: 1.584165, Train accuracy: 0.500000, val accuracy: 0.156250\n",
            "iteration 25\n",
            "Loss: 2.261309, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.435135, Train accuracy: 0.156250, val accuracy: 0.085938\n",
            "Loss: 2.252150, Train accuracy: 0.179688, val accuracy: 0.226562\n",
            "Loss: 2.143087, Train accuracy: 0.218750, val accuracy: 0.140625\n",
            "Loss: 2.173600, Train accuracy: 0.250000, val accuracy: 0.148438\n",
            "Loss: 2.265403, Train accuracy: 0.289062, val accuracy: 0.203125\n",
            "Loss: 2.090558, Train accuracy: 0.281250, val accuracy: 0.218750\n",
            "Loss: 2.277728, Train accuracy: 0.250000, val accuracy: 0.171875\n",
            "Loss: 2.290265, Train accuracy: 0.281250, val accuracy: 0.171875\n",
            "Loss: 1.888877, Train accuracy: 0.296875, val accuracy: 0.171875\n",
            "Loss: 2.011764, Train accuracy: 0.343750, val accuracy: 0.148438\n",
            "Loss: 2.171883, Train accuracy: 0.265625, val accuracy: 0.156250\n",
            "Loss: 1.886088, Train accuracy: 0.273438, val accuracy: 0.164062\n",
            "Loss: 2.037115, Train accuracy: 0.289062, val accuracy: 0.210938\n",
            "Loss: 2.192897, Train accuracy: 0.328125, val accuracy: 0.164062\n",
            "Loss: 2.186472, Train accuracy: 0.265625, val accuracy: 0.140625\n",
            "Loss: 1.934059, Train accuracy: 0.281250, val accuracy: 0.164062\n",
            "Loss: 1.842655, Train accuracy: 0.312500, val accuracy: 0.156250\n",
            "Loss: 2.025427, Train accuracy: 0.351562, val accuracy: 0.156250\n",
            "Loss: 1.961097, Train accuracy: 0.328125, val accuracy: 0.156250\n",
            "Loss: 2.222057, Train accuracy: 0.335938, val accuracy: 0.179688\n",
            "Loss: 2.149754, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.896322, Train accuracy: 0.343750, val accuracy: 0.140625\n",
            "Loss: 2.203597, Train accuracy: 0.343750, val accuracy: 0.164062\n",
            "Loss: 1.954320, Train accuracy: 0.328125, val accuracy: 0.125000\n",
            "Loss: 2.236878, Train accuracy: 0.304688, val accuracy: 0.210938\n",
            "Loss: 1.964520, Train accuracy: 0.421875, val accuracy: 0.117188\n",
            "Loss: 2.298616, Train accuracy: 0.312500, val accuracy: 0.187500\n",
            "Loss: 1.945812, Train accuracy: 0.328125, val accuracy: 0.125000\n",
            "Loss: 1.866261, Train accuracy: 0.335938, val accuracy: 0.171875\n",
            "Loss: 1.910510, Train accuracy: 0.375000, val accuracy: 0.156250\n",
            "Loss: 1.833459, Train accuracy: 0.343750, val accuracy: 0.156250\n",
            "Loss: 1.928333, Train accuracy: 0.343750, val accuracy: 0.148438\n",
            "Loss: 1.753497, Train accuracy: 0.375000, val accuracy: 0.187500\n",
            "Loss: 1.770819, Train accuracy: 0.343750, val accuracy: 0.187500\n",
            "Loss: 1.736679, Train accuracy: 0.421875, val accuracy: 0.164062\n",
            "Loss: 2.081351, Train accuracy: 0.398438, val accuracy: 0.156250\n",
            "Loss: 1.743782, Train accuracy: 0.351562, val accuracy: 0.117188\n",
            "Loss: 1.605160, Train accuracy: 0.406250, val accuracy: 0.156250\n",
            "Loss: 2.086717, Train accuracy: 0.375000, val accuracy: 0.148438\n",
            "Loss: 1.817776, Train accuracy: 0.382812, val accuracy: 0.156250\n",
            "Loss: 1.790492, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.831170, Train accuracy: 0.335938, val accuracy: 0.140625\n",
            "Loss: 2.074947, Train accuracy: 0.328125, val accuracy: 0.164062\n",
            "Loss: 1.906542, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 2.003594, Train accuracy: 0.367188, val accuracy: 0.132812\n",
            "Loss: 2.024614, Train accuracy: 0.414062, val accuracy: 0.148438\n",
            "Loss: 1.691873, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.975191, Train accuracy: 0.406250, val accuracy: 0.148438\n",
            "Loss: 2.150412, Train accuracy: 0.445312, val accuracy: 0.164062\n",
            "iteration 26\n",
            "Loss: 2.400665, Train accuracy: 0.156250, val accuracy: 0.109375\n",
            "Loss: 2.263545, Train accuracy: 0.164062, val accuracy: 0.125000\n",
            "Loss: 3.262516, Train accuracy: 0.187500, val accuracy: 0.250000\n",
            "Loss: 2.443713, Train accuracy: 0.210938, val accuracy: 0.226562\n",
            "Loss: 2.173996, Train accuracy: 0.242188, val accuracy: 0.250000\n",
            "Loss: 2.436446, Train accuracy: 0.226562, val accuracy: 0.242188\n",
            "Loss: 2.500185, Train accuracy: 0.218750, val accuracy: 0.226562\n",
            "Loss: 1.933562, Train accuracy: 0.226562, val accuracy: 0.226562\n",
            "Loss: 1.912951, Train accuracy: 0.226562, val accuracy: 0.218750\n",
            "Loss: 1.931226, Train accuracy: 0.289062, val accuracy: 0.257812\n",
            "Loss: 2.093085, Train accuracy: 0.273438, val accuracy: 0.226562\n",
            "Loss: 2.198402, Train accuracy: 0.289062, val accuracy: 0.242188\n",
            "Loss: 2.012467, Train accuracy: 0.281250, val accuracy: 0.218750\n",
            "Loss: 1.997687, Train accuracy: 0.351562, val accuracy: 0.226562\n",
            "Loss: 2.249800, Train accuracy: 0.265625, val accuracy: 0.210938\n",
            "Loss: 1.991385, Train accuracy: 0.343750, val accuracy: 0.203125\n",
            "Loss: 2.267015, Train accuracy: 0.250000, val accuracy: 0.226562\n",
            "Loss: 1.899950, Train accuracy: 0.304688, val accuracy: 0.242188\n",
            "Loss: 2.114247, Train accuracy: 0.328125, val accuracy: 0.265625\n",
            "Loss: 1.660729, Train accuracy: 0.312500, val accuracy: 0.242188\n",
            "Loss: 2.303424, Train accuracy: 0.328125, val accuracy: 0.234375\n",
            "Loss: 2.110697, Train accuracy: 0.359375, val accuracy: 0.242188\n",
            "Loss: 2.092870, Train accuracy: 0.273438, val accuracy: 0.257812\n",
            "Loss: 1.806876, Train accuracy: 0.320312, val accuracy: 0.226562\n",
            "Loss: 2.261132, Train accuracy: 0.320312, val accuracy: 0.234375\n",
            "Loss: 2.124140, Train accuracy: 0.335938, val accuracy: 0.226562\n",
            "Loss: 2.055724, Train accuracy: 0.320312, val accuracy: 0.281250\n",
            "Loss: 1.882048, Train accuracy: 0.320312, val accuracy: 0.250000\n",
            "Loss: 2.002072, Train accuracy: 0.328125, val accuracy: 0.218750\n",
            "Loss: 2.002724, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 2.251093, Train accuracy: 0.351562, val accuracy: 0.250000\n",
            "Loss: 2.054501, Train accuracy: 0.328125, val accuracy: 0.265625\n",
            "Loss: 2.537309, Train accuracy: 0.312500, val accuracy: 0.265625\n",
            "Loss: 1.844288, Train accuracy: 0.312500, val accuracy: 0.265625\n",
            "Loss: 2.348682, Train accuracy: 0.351562, val accuracy: 0.257812\n",
            "Loss: 1.868297, Train accuracy: 0.335938, val accuracy: 0.273438\n",
            "Loss: 1.952239, Train accuracy: 0.320312, val accuracy: 0.250000\n",
            "Loss: 2.090968, Train accuracy: 0.351562, val accuracy: 0.257812\n",
            "Loss: 2.141451, Train accuracy: 0.343750, val accuracy: 0.242188\n",
            "Loss: 2.013475, Train accuracy: 0.343750, val accuracy: 0.257812\n",
            "Loss: 1.707404, Train accuracy: 0.320312, val accuracy: 0.265625\n",
            "Loss: 1.812765, Train accuracy: 0.343750, val accuracy: 0.234375\n",
            "Loss: 1.954219, Train accuracy: 0.335938, val accuracy: 0.250000\n",
            "Loss: 2.113720, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 2.086443, Train accuracy: 0.335938, val accuracy: 0.265625\n",
            "Loss: 2.019926, Train accuracy: 0.335938, val accuracy: 0.281250\n",
            "Loss: 2.087997, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 1.772596, Train accuracy: 0.359375, val accuracy: 0.250000\n",
            "Loss: 1.595945, Train accuracy: 0.343750, val accuracy: 0.265625\n",
            "Loss: 1.892685, Train accuracy: 0.343750, val accuracy: 0.242188\n",
            "iteration 27\n",
            "Loss: 2.179776, Train accuracy: 0.195312, val accuracy: 0.195312\n",
            "Loss: 2.784222, Train accuracy: 0.179688, val accuracy: 0.117188\n",
            "Loss: 2.760439, Train accuracy: 0.187500, val accuracy: 0.250000\n",
            "Loss: 2.611720, Train accuracy: 0.226562, val accuracy: 0.070312\n",
            "Loss: 2.373908, Train accuracy: 0.203125, val accuracy: 0.109375\n",
            "Loss: 2.174496, Train accuracy: 0.296875, val accuracy: 0.210938\n",
            "Loss: 2.055545, Train accuracy: 0.265625, val accuracy: 0.218750\n",
            "Loss: 2.329594, Train accuracy: 0.281250, val accuracy: 0.156250\n",
            "Loss: 2.026043, Train accuracy: 0.312500, val accuracy: 0.179688\n",
            "Loss: 2.174485, Train accuracy: 0.335938, val accuracy: 0.125000\n",
            "Loss: 1.840533, Train accuracy: 0.289062, val accuracy: 0.101562\n",
            "Loss: 2.271203, Train accuracy: 0.320312, val accuracy: 0.140625\n",
            "Loss: 2.187791, Train accuracy: 0.359375, val accuracy: 0.140625\n",
            "Loss: 1.991108, Train accuracy: 0.343750, val accuracy: 0.195312\n",
            "Loss: 1.796676, Train accuracy: 0.335938, val accuracy: 0.148438\n",
            "Loss: 1.936505, Train accuracy: 0.335938, val accuracy: 0.210938\n",
            "Loss: 1.941714, Train accuracy: 0.351562, val accuracy: 0.179688\n",
            "Loss: 2.012915, Train accuracy: 0.351562, val accuracy: 0.171875\n",
            "Loss: 1.920762, Train accuracy: 0.351562, val accuracy: 0.164062\n",
            "Loss: 1.899660, Train accuracy: 0.382812, val accuracy: 0.210938\n",
            "Loss: 1.684981, Train accuracy: 0.382812, val accuracy: 0.132812\n",
            "Loss: 2.015558, Train accuracy: 0.335938, val accuracy: 0.187500\n",
            "Loss: 2.012125, Train accuracy: 0.367188, val accuracy: 0.226562\n",
            "Loss: 2.028223, Train accuracy: 0.367188, val accuracy: 0.156250\n",
            "Loss: 1.873293, Train accuracy: 0.367188, val accuracy: 0.210938\n",
            "Loss: 1.912208, Train accuracy: 0.359375, val accuracy: 0.179688\n",
            "Loss: 2.014780, Train accuracy: 0.382812, val accuracy: 0.187500\n",
            "Loss: 2.013483, Train accuracy: 0.351562, val accuracy: 0.226562\n",
            "Loss: 1.635534, Train accuracy: 0.343750, val accuracy: 0.140625\n",
            "Loss: 1.634531, Train accuracy: 0.367188, val accuracy: 0.210938\n",
            "Loss: 1.881902, Train accuracy: 0.367188, val accuracy: 0.234375\n",
            "Loss: 1.821042, Train accuracy: 0.367188, val accuracy: 0.203125\n",
            "Loss: 2.031054, Train accuracy: 0.367188, val accuracy: 0.195312\n",
            "Loss: 2.106011, Train accuracy: 0.335938, val accuracy: 0.203125\n",
            "Loss: 1.677172, Train accuracy: 0.351562, val accuracy: 0.156250\n",
            "Loss: 2.021140, Train accuracy: 0.359375, val accuracy: 0.187500\n",
            "Loss: 1.810902, Train accuracy: 0.335938, val accuracy: 0.210938\n",
            "Loss: 1.655695, Train accuracy: 0.328125, val accuracy: 0.195312\n",
            "Loss: 1.922378, Train accuracy: 0.351562, val accuracy: 0.210938\n",
            "Loss: 1.938969, Train accuracy: 0.351562, val accuracy: 0.187500\n",
            "Loss: 1.833956, Train accuracy: 0.351562, val accuracy: 0.187500\n",
            "Loss: 1.925190, Train accuracy: 0.351562, val accuracy: 0.210938\n",
            "Loss: 2.163009, Train accuracy: 0.367188, val accuracy: 0.203125\n",
            "Loss: 1.704269, Train accuracy: 0.351562, val accuracy: 0.195312\n",
            "Loss: 1.910443, Train accuracy: 0.328125, val accuracy: 0.171875\n",
            "Loss: 1.802660, Train accuracy: 0.335938, val accuracy: 0.187500\n",
            "Loss: 1.995351, Train accuracy: 0.359375, val accuracy: 0.218750\n",
            "Loss: 1.787501, Train accuracy: 0.359375, val accuracy: 0.218750\n",
            "Loss: 1.663756, Train accuracy: 0.351562, val accuracy: 0.210938\n",
            "Loss: 1.895524, Train accuracy: 0.351562, val accuracy: 0.195312\n",
            "iteration 28\n",
            "Loss: 3.965119, Train accuracy: 0.140625, val accuracy: 0.101562\n",
            "Loss: 5.164610, Train accuracy: 0.203125, val accuracy: 0.257812\n",
            "Loss: 3.850562, Train accuracy: 0.156250, val accuracy: 0.148438\n",
            "Loss: 2.485101, Train accuracy: 0.242188, val accuracy: 0.210938\n",
            "Loss: 3.400449, Train accuracy: 0.242188, val accuracy: 0.132812\n",
            "Loss: 2.364573, Train accuracy: 0.171875, val accuracy: 0.132812\n",
            "Loss: 1.847159, Train accuracy: 0.226562, val accuracy: 0.273438\n",
            "Loss: 3.407466, Train accuracy: 0.210938, val accuracy: 0.265625\n",
            "Loss: 2.026670, Train accuracy: 0.257812, val accuracy: 0.125000\n",
            "Loss: 2.235620, Train accuracy: 0.226562, val accuracy: 0.171875\n",
            "Loss: 1.957690, Train accuracy: 0.390625, val accuracy: 0.257812\n",
            "Loss: 2.887129, Train accuracy: 0.289062, val accuracy: 0.203125\n",
            "Loss: 4.674822, Train accuracy: 0.343750, val accuracy: 0.218750\n",
            "Loss: 2.457318, Train accuracy: 0.343750, val accuracy: 0.226562\n",
            "Loss: 1.838446, Train accuracy: 0.351562, val accuracy: 0.218750\n",
            "Loss: 1.633768, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 2.020754, Train accuracy: 0.390625, val accuracy: 0.234375\n",
            "Loss: 2.061467, Train accuracy: 0.304688, val accuracy: 0.203125\n",
            "Loss: 2.293189, Train accuracy: 0.382812, val accuracy: 0.171875\n",
            "Loss: 1.879888, Train accuracy: 0.359375, val accuracy: 0.109375\n",
            "Loss: 2.176878, Train accuracy: 0.429688, val accuracy: 0.218750\n",
            "Loss: 2.013167, Train accuracy: 0.414062, val accuracy: 0.210938\n",
            "Loss: 1.425766, Train accuracy: 0.453125, val accuracy: 0.250000\n",
            "Loss: 1.091891, Train accuracy: 0.539062, val accuracy: 0.218750\n",
            "Loss: 1.690031, Train accuracy: 0.367188, val accuracy: 0.265625\n",
            "Loss: 1.808618, Train accuracy: 0.468750, val accuracy: 0.187500\n",
            "Loss: 1.193428, Train accuracy: 0.500000, val accuracy: 0.203125\n",
            "Loss: 1.672381, Train accuracy: 0.523438, val accuracy: 0.203125\n",
            "Loss: 1.577669, Train accuracy: 0.492188, val accuracy: 0.242188\n",
            "Loss: 1.431027, Train accuracy: 0.562500, val accuracy: 0.226562\n",
            "Loss: 1.661744, Train accuracy: 0.578125, val accuracy: 0.218750\n",
            "Loss: 1.691204, Train accuracy: 0.531250, val accuracy: 0.210938\n",
            "Loss: 1.400234, Train accuracy: 0.500000, val accuracy: 0.164062\n",
            "Loss: 1.648690, Train accuracy: 0.554688, val accuracy: 0.187500\n",
            "Loss: 2.132202, Train accuracy: 0.585938, val accuracy: 0.218750\n",
            "Loss: 1.235072, Train accuracy: 0.562500, val accuracy: 0.250000\n",
            "Loss: 1.635678, Train accuracy: 0.671875, val accuracy: 0.250000\n",
            "Loss: 1.295839, Train accuracy: 0.562500, val accuracy: 0.250000\n",
            "Loss: 1.355336, Train accuracy: 0.554688, val accuracy: 0.195312\n",
            "Loss: 0.981641, Train accuracy: 0.640625, val accuracy: 0.203125\n",
            "Loss: 1.137905, Train accuracy: 0.601562, val accuracy: 0.203125\n",
            "Loss: 1.302743, Train accuracy: 0.601562, val accuracy: 0.148438\n",
            "Loss: 1.026408, Train accuracy: 0.625000, val accuracy: 0.257812\n",
            "Loss: 1.180339, Train accuracy: 0.632812, val accuracy: 0.242188\n",
            "Loss: 1.144235, Train accuracy: 0.664062, val accuracy: 0.187500\n",
            "Loss: 1.059643, Train accuracy: 0.648438, val accuracy: 0.234375\n",
            "Loss: 2.246540, Train accuracy: 0.585938, val accuracy: 0.265625\n",
            "Loss: 1.443876, Train accuracy: 0.656250, val accuracy: 0.203125\n",
            "Loss: 1.651999, Train accuracy: 0.679688, val accuracy: 0.234375\n",
            "Loss: 1.079793, Train accuracy: 0.664062, val accuracy: 0.203125\n",
            "iteration 29\n",
            "Loss: 2.134139, Train accuracy: 0.179688, val accuracy: 0.250000\n",
            "Loss: 2.278799, Train accuracy: 0.171875, val accuracy: 0.062500\n",
            "Loss: 2.246609, Train accuracy: 0.187500, val accuracy: 0.250000\n",
            "Loss: 2.292466, Train accuracy: 0.210938, val accuracy: 0.171875\n",
            "Loss: 1.865085, Train accuracy: 0.257812, val accuracy: 0.148438\n",
            "Loss: 2.041630, Train accuracy: 0.296875, val accuracy: 0.203125\n",
            "Loss: 2.275429, Train accuracy: 0.304688, val accuracy: 0.171875\n",
            "Loss: 2.032498, Train accuracy: 0.320312, val accuracy: 0.187500\n",
            "Loss: 2.001339, Train accuracy: 0.343750, val accuracy: 0.210938\n",
            "Loss: 2.575352, Train accuracy: 0.273438, val accuracy: 0.140625\n",
            "Loss: 2.458521, Train accuracy: 0.265625, val accuracy: 0.203125\n",
            "Loss: 2.060650, Train accuracy: 0.328125, val accuracy: 0.164062\n",
            "Loss: 1.788985, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 1.695740, Train accuracy: 0.367188, val accuracy: 0.140625\n",
            "Loss: 1.961586, Train accuracy: 0.375000, val accuracy: 0.164062\n",
            "Loss: 2.350164, Train accuracy: 0.367188, val accuracy: 0.218750\n",
            "Loss: 1.850452, Train accuracy: 0.406250, val accuracy: 0.218750\n",
            "Loss: 1.728927, Train accuracy: 0.367188, val accuracy: 0.210938\n",
            "Loss: 1.936459, Train accuracy: 0.398438, val accuracy: 0.140625\n",
            "Loss: 1.576711, Train accuracy: 0.437500, val accuracy: 0.164062\n",
            "Loss: 1.565125, Train accuracy: 0.437500, val accuracy: 0.203125\n",
            "Loss: 1.765949, Train accuracy: 0.429688, val accuracy: 0.171875\n",
            "Loss: 1.943343, Train accuracy: 0.453125, val accuracy: 0.210938\n",
            "Loss: 1.672874, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 1.869691, Train accuracy: 0.445312, val accuracy: 0.179688\n",
            "Loss: 2.013360, Train accuracy: 0.476562, val accuracy: 0.148438\n",
            "Loss: 1.733358, Train accuracy: 0.460938, val accuracy: 0.156250\n",
            "Loss: 2.056310, Train accuracy: 0.476562, val accuracy: 0.179688\n",
            "Loss: 1.622689, Train accuracy: 0.398438, val accuracy: 0.195312\n",
            "Loss: 1.565770, Train accuracy: 0.484375, val accuracy: 0.101562\n",
            "Loss: 1.733236, Train accuracy: 0.414062, val accuracy: 0.203125\n",
            "Loss: 1.780794, Train accuracy: 0.484375, val accuracy: 0.101562\n",
            "Loss: 1.715907, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 2.092874, Train accuracy: 0.531250, val accuracy: 0.125000\n",
            "Loss: 1.769519, Train accuracy: 0.468750, val accuracy: 0.203125\n",
            "Loss: 1.764907, Train accuracy: 0.515625, val accuracy: 0.117188\n",
            "Loss: 1.416706, Train accuracy: 0.437500, val accuracy: 0.179688\n",
            "Loss: 1.504511, Train accuracy: 0.539062, val accuracy: 0.164062\n",
            "Loss: 1.431158, Train accuracy: 0.539062, val accuracy: 0.148438\n",
            "Loss: 1.410216, Train accuracy: 0.539062, val accuracy: 0.179688\n",
            "Loss: 1.738869, Train accuracy: 0.546875, val accuracy: 0.140625\n",
            "Loss: 1.527275, Train accuracy: 0.570312, val accuracy: 0.179688\n",
            "Loss: 1.416270, Train accuracy: 0.570312, val accuracy: 0.156250\n",
            "Loss: 1.538484, Train accuracy: 0.578125, val accuracy: 0.171875\n",
            "Loss: 1.593424, Train accuracy: 0.570312, val accuracy: 0.164062\n",
            "Loss: 1.703832, Train accuracy: 0.570312, val accuracy: 0.125000\n",
            "Loss: 1.539262, Train accuracy: 0.554688, val accuracy: 0.156250\n",
            "Loss: 1.701377, Train accuracy: 0.617188, val accuracy: 0.132812\n",
            "Loss: 1.888171, Train accuracy: 0.562500, val accuracy: 0.179688\n",
            "Loss: 1.692673, Train accuracy: 0.585938, val accuracy: 0.125000\n",
            "iteration 30\n",
            "Loss: 3.128874, Train accuracy: 0.179688, val accuracy: 0.257812\n",
            "Loss: 3.081599, Train accuracy: 0.164062, val accuracy: 0.070312\n",
            "Loss: 2.111551, Train accuracy: 0.179688, val accuracy: 0.132812\n",
            "Loss: 2.754767, Train accuracy: 0.242188, val accuracy: 0.179688\n",
            "Loss: 1.860479, Train accuracy: 0.218750, val accuracy: 0.187500\n",
            "Loss: 2.344776, Train accuracy: 0.312500, val accuracy: 0.179688\n",
            "Loss: 2.235092, Train accuracy: 0.242188, val accuracy: 0.109375\n",
            "Loss: 1.842682, Train accuracy: 0.273438, val accuracy: 0.171875\n",
            "Loss: 1.765958, Train accuracy: 0.304688, val accuracy: 0.179688\n",
            "Loss: 2.597741, Train accuracy: 0.242188, val accuracy: 0.109375\n",
            "Loss: 1.827010, Train accuracy: 0.304688, val accuracy: 0.101562\n",
            "Loss: 2.037398, Train accuracy: 0.304688, val accuracy: 0.226562\n",
            "Loss: 1.879223, Train accuracy: 0.375000, val accuracy: 0.226562\n",
            "Loss: 1.875564, Train accuracy: 0.304688, val accuracy: 0.140625\n",
            "Loss: 1.842430, Train accuracy: 0.328125, val accuracy: 0.156250\n",
            "Loss: 2.086730, Train accuracy: 0.296875, val accuracy: 0.226562\n",
            "Loss: 1.478708, Train accuracy: 0.351562, val accuracy: 0.203125\n",
            "Loss: 1.363453, Train accuracy: 0.367188, val accuracy: 0.164062\n",
            "Loss: 1.687642, Train accuracy: 0.382812, val accuracy: 0.164062\n",
            "Loss: 2.305353, Train accuracy: 0.437500, val accuracy: 0.171875\n",
            "Loss: 2.079798, Train accuracy: 0.367188, val accuracy: 0.242188\n",
            "Loss: 2.022599, Train accuracy: 0.414062, val accuracy: 0.164062\n",
            "Loss: 2.168104, Train accuracy: 0.390625, val accuracy: 0.234375\n",
            "Loss: 1.895198, Train accuracy: 0.429688, val accuracy: 0.171875\n",
            "Loss: 1.963460, Train accuracy: 0.414062, val accuracy: 0.179688\n",
            "Loss: 1.876238, Train accuracy: 0.437500, val accuracy: 0.203125\n",
            "Loss: 1.928760, Train accuracy: 0.421875, val accuracy: 0.187500\n",
            "Loss: 1.790683, Train accuracy: 0.453125, val accuracy: 0.210938\n",
            "Loss: 1.878101, Train accuracy: 0.453125, val accuracy: 0.226562\n",
            "Loss: 1.166985, Train accuracy: 0.476562, val accuracy: 0.203125\n",
            "Loss: 1.489538, Train accuracy: 0.421875, val accuracy: 0.195312\n",
            "Loss: 1.519145, Train accuracy: 0.453125, val accuracy: 0.187500\n",
            "Loss: 1.464683, Train accuracy: 0.445312, val accuracy: 0.210938\n",
            "Loss: 1.874638, Train accuracy: 0.437500, val accuracy: 0.203125\n",
            "Loss: 1.616205, Train accuracy: 0.460938, val accuracy: 0.195312\n",
            "Loss: 1.878027, Train accuracy: 0.460938, val accuracy: 0.210938\n",
            "Loss: 1.473892, Train accuracy: 0.460938, val accuracy: 0.203125\n",
            "Loss: 1.725657, Train accuracy: 0.484375, val accuracy: 0.203125\n",
            "Loss: 1.466964, Train accuracy: 0.484375, val accuracy: 0.226562\n",
            "Loss: 1.793102, Train accuracy: 0.468750, val accuracy: 0.226562\n",
            "Loss: 1.864046, Train accuracy: 0.484375, val accuracy: 0.195312\n",
            "Loss: 1.617248, Train accuracy: 0.460938, val accuracy: 0.195312\n",
            "Loss: 1.762873, Train accuracy: 0.468750, val accuracy: 0.210938\n",
            "Loss: 1.959150, Train accuracy: 0.484375, val accuracy: 0.203125\n",
            "Loss: 1.444660, Train accuracy: 0.460938, val accuracy: 0.195312\n",
            "Loss: 1.565150, Train accuracy: 0.460938, val accuracy: 0.218750\n",
            "Loss: 1.495599, Train accuracy: 0.484375, val accuracy: 0.203125\n",
            "Loss: 1.144705, Train accuracy: 0.476562, val accuracy: 0.187500\n",
            "Loss: 1.260856, Train accuracy: 0.484375, val accuracy: 0.203125\n",
            "Loss: 1.369782, Train accuracy: 0.500000, val accuracy: 0.218750\n",
            "iteration 31\n",
            "Loss: 2.462727, Train accuracy: 0.164062, val accuracy: 0.085938\n",
            "Loss: 2.288923, Train accuracy: 0.203125, val accuracy: 0.242188\n",
            "Loss: 2.499098, Train accuracy: 0.179688, val accuracy: 0.109375\n",
            "Loss: 1.944310, Train accuracy: 0.265625, val accuracy: 0.257812\n",
            "Loss: 2.140846, Train accuracy: 0.289062, val accuracy: 0.179688\n",
            "Loss: 2.296950, Train accuracy: 0.250000, val accuracy: 0.257812\n",
            "Loss: 2.087469, Train accuracy: 0.218750, val accuracy: 0.140625\n",
            "Loss: 2.233229, Train accuracy: 0.265625, val accuracy: 0.234375\n",
            "Loss: 2.318523, Train accuracy: 0.289062, val accuracy: 0.109375\n",
            "Loss: 2.020527, Train accuracy: 0.312500, val accuracy: 0.210938\n",
            "Loss: 2.309135, Train accuracy: 0.335938, val accuracy: 0.242188\n",
            "Loss: 2.258670, Train accuracy: 0.359375, val accuracy: 0.179688\n",
            "Loss: 1.956041, Train accuracy: 0.367188, val accuracy: 0.218750\n",
            "Loss: 1.677719, Train accuracy: 0.382812, val accuracy: 0.195312\n",
            "Loss: 1.898159, Train accuracy: 0.335938, val accuracy: 0.218750\n",
            "Loss: 2.012626, Train accuracy: 0.382812, val accuracy: 0.234375\n",
            "Loss: 2.065834, Train accuracy: 0.343750, val accuracy: 0.187500\n",
            "Loss: 1.741443, Train accuracy: 0.414062, val accuracy: 0.210938\n",
            "Loss: 1.573981, Train accuracy: 0.359375, val accuracy: 0.195312\n",
            "Loss: 1.801939, Train accuracy: 0.382812, val accuracy: 0.210938\n",
            "Loss: 2.040759, Train accuracy: 0.406250, val accuracy: 0.226562\n",
            "Loss: 2.145708, Train accuracy: 0.421875, val accuracy: 0.226562\n",
            "Loss: 1.861915, Train accuracy: 0.367188, val accuracy: 0.218750\n",
            "Loss: 1.936092, Train accuracy: 0.406250, val accuracy: 0.234375\n",
            "Loss: 1.823782, Train accuracy: 0.406250, val accuracy: 0.210938\n",
            "Loss: 1.833666, Train accuracy: 0.414062, val accuracy: 0.226562\n",
            "Loss: 2.088040, Train accuracy: 0.445312, val accuracy: 0.242188\n",
            "Loss: 1.707430, Train accuracy: 0.406250, val accuracy: 0.218750\n",
            "Loss: 1.888309, Train accuracy: 0.406250, val accuracy: 0.226562\n",
            "Loss: 1.953751, Train accuracy: 0.445312, val accuracy: 0.226562\n",
            "Loss: 1.858605, Train accuracy: 0.484375, val accuracy: 0.250000\n",
            "Loss: 1.698150, Train accuracy: 0.421875, val accuracy: 0.250000\n",
            "Loss: 1.952116, Train accuracy: 0.414062, val accuracy: 0.218750\n",
            "Loss: 1.763242, Train accuracy: 0.437500, val accuracy: 0.218750\n",
            "Loss: 1.932598, Train accuracy: 0.437500, val accuracy: 0.226562\n",
            "Loss: 1.853760, Train accuracy: 0.437500, val accuracy: 0.218750\n",
            "Loss: 2.200413, Train accuracy: 0.421875, val accuracy: 0.242188\n",
            "Loss: 1.768792, Train accuracy: 0.437500, val accuracy: 0.226562\n",
            "Loss: 1.498707, Train accuracy: 0.453125, val accuracy: 0.234375\n",
            "Loss: 1.644166, Train accuracy: 0.460938, val accuracy: 0.242188\n",
            "Loss: 1.895356, Train accuracy: 0.468750, val accuracy: 0.257812\n",
            "Loss: 1.770162, Train accuracy: 0.445312, val accuracy: 0.257812\n",
            "Loss: 1.926269, Train accuracy: 0.460938, val accuracy: 0.250000\n",
            "Loss: 1.495697, Train accuracy: 0.468750, val accuracy: 0.226562\n",
            "Loss: 1.536814, Train accuracy: 0.460938, val accuracy: 0.226562\n",
            "Loss: 1.978691, Train accuracy: 0.453125, val accuracy: 0.218750\n",
            "Loss: 1.622699, Train accuracy: 0.468750, val accuracy: 0.242188\n",
            "Loss: 1.956586, Train accuracy: 0.492188, val accuracy: 0.257812\n",
            "Loss: 1.712757, Train accuracy: 0.476562, val accuracy: 0.250000\n",
            "Loss: 1.957849, Train accuracy: 0.460938, val accuracy: 0.250000\n",
            "iteration 32\n",
            "learning_rate=0.01, decay=0.999, conv1=8, conv2=8, bs=8\n",
            "best train accuracy achieved: 0.921875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNloJd87Bl2f",
        "outputId": "35639500-ff39-4374-9b18-2212c566165a"
      },
      "source": [
        "data_size = 128\n",
        "\n",
        "learning_rate = 1e-3\n",
        "decay = 0.9999\n",
        "batch_size = 8\n",
        "\n",
        "model = ConvNet(input_shape=(32,32,3), n_output_classes=10, \n",
        "                              conv1_channels=20,\n",
        "                              conv2_channels=8)\n",
        "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
        "# TODO: Change any hyperparamers or optimizators to reach 1.0 training accuracy in 50 epochs or less\n",
        "# Hint: If you have hard time finding the right parameters manually, try grid search or random search!\n",
        "trainer = Trainer(model, dataset, MomentumSGD(), \n",
        "                  learning_rate=learning_rate,\n",
        "                  num_epochs=200,\n",
        "                  batch_size=batch_size,\n",
        "                  learning_rate_decay=decay)\n",
        "loss_history, train_history, val_history = trainer.fit()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 5.302884, Train accuracy: 0.195312, val accuracy: 0.109375\n",
            "Loss: 3.260982, Train accuracy: 0.101562, val accuracy: 0.101562\n",
            "Loss: 2.491365, Train accuracy: 0.273438, val accuracy: 0.171875\n",
            "Loss: 3.123338, Train accuracy: 0.273438, val accuracy: 0.226562\n",
            "Loss: 4.432654, Train accuracy: 0.265625, val accuracy: 0.109375\n",
            "Loss: 4.973287, Train accuracy: 0.210938, val accuracy: 0.164062\n",
            "Loss: 2.020665, Train accuracy: 0.328125, val accuracy: 0.179688\n",
            "Loss: 2.328198, Train accuracy: 0.414062, val accuracy: 0.203125\n",
            "Loss: 2.693755, Train accuracy: 0.421875, val accuracy: 0.179688\n",
            "Loss: 2.068404, Train accuracy: 0.382812, val accuracy: 0.171875\n",
            "Loss: 2.116813, Train accuracy: 0.398438, val accuracy: 0.140625\n",
            "Loss: 2.395889, Train accuracy: 0.234375, val accuracy: 0.093750\n",
            "Loss: 1.913830, Train accuracy: 0.507812, val accuracy: 0.125000\n",
            "Loss: 1.236069, Train accuracy: 0.460938, val accuracy: 0.195312\n",
            "Loss: 2.009523, Train accuracy: 0.539062, val accuracy: 0.234375\n",
            "Loss: 2.701031, Train accuracy: 0.335938, val accuracy: 0.234375\n",
            "Loss: 1.316065, Train accuracy: 0.500000, val accuracy: 0.187500\n",
            "Loss: 1.156604, Train accuracy: 0.523438, val accuracy: 0.242188\n",
            "Loss: 1.413869, Train accuracy: 0.554688, val accuracy: 0.250000\n",
            "Loss: 2.084179, Train accuracy: 0.523438, val accuracy: 0.203125\n",
            "Loss: 0.907036, Train accuracy: 0.507812, val accuracy: 0.117188\n",
            "Loss: 1.899241, Train accuracy: 0.484375, val accuracy: 0.187500\n",
            "Loss: 3.552843, Train accuracy: 0.578125, val accuracy: 0.179688\n",
            "Loss: 1.158244, Train accuracy: 0.546875, val accuracy: 0.210938\n",
            "Loss: 1.647549, Train accuracy: 0.546875, val accuracy: 0.195312\n",
            "Loss: 1.208178, Train accuracy: 0.546875, val accuracy: 0.156250\n",
            "Loss: 0.840912, Train accuracy: 0.578125, val accuracy: 0.140625\n",
            "Loss: 1.956350, Train accuracy: 0.445312, val accuracy: 0.171875\n",
            "Loss: 1.474620, Train accuracy: 0.632812, val accuracy: 0.210938\n",
            "Loss: 1.163757, Train accuracy: 0.632812, val accuracy: 0.187500\n",
            "Loss: 0.856832, Train accuracy: 0.578125, val accuracy: 0.195312\n",
            "Loss: 1.205227, Train accuracy: 0.648438, val accuracy: 0.179688\n",
            "Loss: 1.045474, Train accuracy: 0.656250, val accuracy: 0.179688\n",
            "Loss: 1.168111, Train accuracy: 0.648438, val accuracy: 0.187500\n",
            "Loss: 0.504777, Train accuracy: 0.718750, val accuracy: 0.218750\n",
            "Loss: 1.072495, Train accuracy: 0.679688, val accuracy: 0.203125\n",
            "Loss: 1.228103, Train accuracy: 0.671875, val accuracy: 0.218750\n",
            "Loss: 0.709215, Train accuracy: 0.703125, val accuracy: 0.203125\n",
            "Loss: 1.157083, Train accuracy: 0.710938, val accuracy: 0.195312\n",
            "Loss: 0.833029, Train accuracy: 0.625000, val accuracy: 0.203125\n",
            "Loss: 0.494596, Train accuracy: 0.773438, val accuracy: 0.203125\n",
            "Loss: 0.668146, Train accuracy: 0.742188, val accuracy: 0.195312\n",
            "Loss: 1.693348, Train accuracy: 0.750000, val accuracy: 0.195312\n",
            "Loss: 1.208834, Train accuracy: 0.734375, val accuracy: 0.179688\n",
            "Loss: 0.995644, Train accuracy: 0.757812, val accuracy: 0.179688\n",
            "Loss: 1.318781, Train accuracy: 0.804688, val accuracy: 0.203125\n",
            "Loss: 1.424404, Train accuracy: 0.695312, val accuracy: 0.203125\n",
            "Loss: 1.429806, Train accuracy: 0.742188, val accuracy: 0.226562\n",
            "Loss: 0.659040, Train accuracy: 0.804688, val accuracy: 0.195312\n",
            "Loss: 0.768306, Train accuracy: 0.687500, val accuracy: 0.203125\n",
            "Loss: 0.866172, Train accuracy: 0.781250, val accuracy: 0.195312\n",
            "Loss: 0.736306, Train accuracy: 0.804688, val accuracy: 0.179688\n",
            "Loss: 1.094502, Train accuracy: 0.789062, val accuracy: 0.156250\n",
            "Loss: 0.925903, Train accuracy: 0.703125, val accuracy: 0.171875\n",
            "Loss: 0.673723, Train accuracy: 0.789062, val accuracy: 0.179688\n",
            "Loss: 0.896217, Train accuracy: 0.812500, val accuracy: 0.203125\n",
            "Loss: 0.754105, Train accuracy: 0.796875, val accuracy: 0.218750\n",
            "Loss: 0.650297, Train accuracy: 0.820312, val accuracy: 0.187500\n",
            "Loss: 0.450210, Train accuracy: 0.773438, val accuracy: 0.179688\n",
            "Loss: 0.521600, Train accuracy: 0.835938, val accuracy: 0.195312\n",
            "Loss: 0.609811, Train accuracy: 0.859375, val accuracy: 0.203125\n",
            "Loss: 0.706461, Train accuracy: 0.757812, val accuracy: 0.203125\n",
            "Loss: 0.927771, Train accuracy: 0.820312, val accuracy: 0.195312\n",
            "Loss: 0.701493, Train accuracy: 0.796875, val accuracy: 0.210938\n",
            "Loss: 0.534273, Train accuracy: 0.875000, val accuracy: 0.156250\n",
            "Loss: 0.557477, Train accuracy: 0.875000, val accuracy: 0.195312\n",
            "Loss: 0.631745, Train accuracy: 0.835938, val accuracy: 0.179688\n",
            "Loss: 0.884563, Train accuracy: 0.820312, val accuracy: 0.210938\n",
            "Loss: 0.438901, Train accuracy: 0.843750, val accuracy: 0.187500\n",
            "Loss: 0.722082, Train accuracy: 0.867188, val accuracy: 0.187500\n",
            "Loss: 0.499440, Train accuracy: 0.859375, val accuracy: 0.195312\n",
            "Loss: 0.345654, Train accuracy: 0.828125, val accuracy: 0.210938\n",
            "Loss: 0.625673, Train accuracy: 0.804688, val accuracy: 0.187500\n",
            "Loss: 0.271090, Train accuracy: 0.875000, val accuracy: 0.195312\n",
            "Loss: 0.851764, Train accuracy: 0.859375, val accuracy: 0.210938\n",
            "Loss: 0.331630, Train accuracy: 0.859375, val accuracy: 0.164062\n",
            "Loss: 0.676717, Train accuracy: 0.890625, val accuracy: 0.226562\n",
            "Loss: 0.219963, Train accuracy: 0.835938, val accuracy: 0.171875\n",
            "Loss: 0.324843, Train accuracy: 0.929688, val accuracy: 0.210938\n",
            "Loss: 0.445611, Train accuracy: 0.929688, val accuracy: 0.179688\n",
            "Loss: 0.645090, Train accuracy: 0.906250, val accuracy: 0.195312\n",
            "Loss: 0.881109, Train accuracy: 0.906250, val accuracy: 0.203125\n",
            "Loss: 0.664439, Train accuracy: 0.875000, val accuracy: 0.179688\n",
            "Loss: 0.211165, Train accuracy: 0.921875, val accuracy: 0.195312\n",
            "Loss: 0.258259, Train accuracy: 0.890625, val accuracy: 0.171875\n",
            "Loss: 0.621864, Train accuracy: 0.953125, val accuracy: 0.187500\n",
            "Loss: 0.381071, Train accuracy: 0.945312, val accuracy: 0.203125\n",
            "Loss: 0.832021, Train accuracy: 0.960938, val accuracy: 0.179688\n",
            "Loss: 0.549598, Train accuracy: 0.968750, val accuracy: 0.226562\n",
            "Loss: 0.572518, Train accuracy: 0.906250, val accuracy: 0.203125\n",
            "Loss: 0.705079, Train accuracy: 0.898438, val accuracy: 0.187500\n",
            "Loss: 0.668736, Train accuracy: 0.960938, val accuracy: 0.210938\n",
            "Loss: 0.517121, Train accuracy: 0.906250, val accuracy: 0.171875\n",
            "Loss: 0.711190, Train accuracy: 0.937500, val accuracy: 0.218750\n",
            "Loss: 0.840698, Train accuracy: 0.953125, val accuracy: 0.195312\n",
            "Loss: 0.335571, Train accuracy: 0.929688, val accuracy: 0.195312\n",
            "Loss: 0.445336, Train accuracy: 0.976562, val accuracy: 0.187500\n",
            "Loss: 0.170128, Train accuracy: 0.968750, val accuracy: 0.195312\n",
            "Loss: 0.658539, Train accuracy: 0.929688, val accuracy: 0.187500\n",
            "Loss: 0.314652, Train accuracy: 0.968750, val accuracy: 0.171875\n",
            "Loss: 0.875580, Train accuracy: 0.835938, val accuracy: 0.250000\n",
            "Loss: 0.464296, Train accuracy: 0.960938, val accuracy: 0.210938\n",
            "Loss: 0.167819, Train accuracy: 0.976562, val accuracy: 0.195312\n",
            "Loss: 0.532622, Train accuracy: 0.968750, val accuracy: 0.210938\n",
            "Loss: 0.325499, Train accuracy: 0.984375, val accuracy: 0.203125\n",
            "Loss: 0.542754, Train accuracy: 0.968750, val accuracy: 0.171875\n",
            "Loss: 0.139492, Train accuracy: 0.976562, val accuracy: 0.218750\n",
            "Loss: 0.190543, Train accuracy: 0.976562, val accuracy: 0.171875\n",
            "Loss: 0.493469, Train accuracy: 0.984375, val accuracy: 0.218750\n",
            "Loss: 0.475482, Train accuracy: 0.976562, val accuracy: 0.179688\n",
            "Loss: 0.201128, Train accuracy: 0.968750, val accuracy: 0.195312\n",
            "Loss: 0.237945, Train accuracy: 0.976562, val accuracy: 0.179688\n",
            "Loss: 0.411633, Train accuracy: 0.984375, val accuracy: 0.195312\n",
            "Loss: 0.245166, Train accuracy: 0.984375, val accuracy: 0.187500\n",
            "Loss: 0.362857, Train accuracy: 0.984375, val accuracy: 0.195312\n",
            "Loss: 0.294855, Train accuracy: 0.992188, val accuracy: 0.195312\n",
            "Loss: 0.184650, Train accuracy: 0.984375, val accuracy: 0.187500\n",
            "Loss: 0.254052, Train accuracy: 0.984375, val accuracy: 0.187500\n",
            "Loss: 0.365520, Train accuracy: 0.992188, val accuracy: 0.203125\n",
            "Loss: 0.130299, Train accuracy: 0.984375, val accuracy: 0.210938\n",
            "Loss: 0.196539, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.251152, Train accuracy: 0.984375, val accuracy: 0.195312\n",
            "Loss: 0.186814, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.209703, Train accuracy: 0.953125, val accuracy: 0.210938\n",
            "Loss: 0.401203, Train accuracy: 0.984375, val accuracy: 0.179688\n",
            "Loss: 0.154658, Train accuracy: 0.984375, val accuracy: 0.218750\n",
            "Loss: 0.140727, Train accuracy: 0.992188, val accuracy: 0.171875\n",
            "Loss: 0.385018, Train accuracy: 0.992188, val accuracy: 0.210938\n",
            "Loss: 0.152655, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.141591, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.117888, Train accuracy: 1.000000, val accuracy: 0.203125\n",
            "Loss: 0.136224, Train accuracy: 0.992188, val accuracy: 0.171875\n",
            "Loss: 0.245552, Train accuracy: 0.960938, val accuracy: 0.226562\n",
            "Loss: 0.097727, Train accuracy: 0.976562, val accuracy: 0.226562\n",
            "Loss: 0.131834, Train accuracy: 0.992188, val accuracy: 0.171875\n",
            "Loss: 0.180029, Train accuracy: 0.976562, val accuracy: 0.218750\n",
            "Loss: 0.147054, Train accuracy: 0.992188, val accuracy: 0.164062\n",
            "Loss: 0.101247, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.218665, Train accuracy: 0.992188, val accuracy: 0.195312\n",
            "Loss: 0.160248, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.181061, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.181393, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.175499, Train accuracy: 0.992188, val accuracy: 0.195312\n",
            "Loss: 0.241436, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.082921, Train accuracy: 0.992188, val accuracy: 0.179688\n",
            "Loss: 0.305632, Train accuracy: 0.976562, val accuracy: 0.203125\n",
            "Loss: 0.198794, Train accuracy: 0.992188, val accuracy: 0.179688\n",
            "Loss: 0.133698, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.190059, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.119387, Train accuracy: 0.992188, val accuracy: 0.195312\n",
            "Loss: 0.077056, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.219077, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.104086, Train accuracy: 0.992188, val accuracy: 0.187500\n",
            "Loss: 0.227647, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.050917, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.227666, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.252414, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.117653, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.136858, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.104398, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.147588, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.129082, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.111110, Train accuracy: 0.992188, val accuracy: 0.195312\n",
            "Loss: 0.184151, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.069057, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.169748, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.063965, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.120178, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.198675, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.133748, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.052293, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.163667, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.157074, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.132914, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.120533, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.087053, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.124959, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.124311, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.097030, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.061950, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.067490, Train accuracy: 1.000000, val accuracy: 0.164062\n",
            "Loss: 0.120515, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.107828, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.095468, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.093883, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.139614, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.215797, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.150688, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.056238, Train accuracy: 1.000000, val accuracy: 0.179688\n",
            "Loss: 0.104491, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.121563, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.109471, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.113707, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.068860, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.135597, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.065800, Train accuracy: 1.000000, val accuracy: 0.171875\n",
            "Loss: 0.123841, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.071405, Train accuracy: 1.000000, val accuracy: 0.164062\n",
            "Loss: 0.055166, Train accuracy: 1.000000, val accuracy: 0.187500\n",
            "Loss: 0.083518, Train accuracy: 1.000000, val accuracy: 0.164062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeKcTNoGhdB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "338aba9a-1d2f-447d-9289-924d60136378"
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(val_history)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa1e70ba290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9v_ggVShdB-"
      },
      "source": [
        "Дальнейшие упражнения - уже на PyTorch, открывайте следующий notebook!\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UeJDxHThdB_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}